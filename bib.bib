
@article{batesFittingLinearMixedeffects2015,
  title = {Fitting Linear Mixed-Effects Models Using Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  year = {2015},
  volume = {67},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
  journal = {Journal of Statistical Software},
  number = {1}
}

@book{brennanGeneralizabilityTheory2001,
  title = {Generalizability {{Theory}}},
  author = {Brennan, Robert L.},
  year = {2001},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  doi = {10.1007/978-1-4757-3456-0},
  url = {https://www.springer.com/us/book/9780387952826},
  urldate = {2020-09-17},
  abstract = {In 1972 a monograph by Cronbach, Gleser, Nanda, and Rajaratnam was published entitled The Dependability of Behavioral Measurements. That book incorporated, systematized, and extended their previous research into what came to be called generalizability theory, which liberalizes classical test theory, in part through the application of analysis of variance proce\- dures that focus on variance components. Generalizability theory is perhaps the most broadly defined measurement model currently in existence, and the Cronbach et al. (1972) treatment of the theory represents a major con\- tribution to psychometrics. However, as Cronbach et al. (1972, p. 3) state, their book is "complexly organized and by no means simple to follow" and, of course, it is nearly 30 years old. In 1983, ACT, Inc. published my monograph entitled Elements of Gen\- eralizability Theory, with a slightly revised version appearing in 1992. That treatment is considerably less comprehensive than Cronbach et al. (1972) but still detailed enough to convey much ofthe richness of the theory and to facilitate its application. However, the 1983/1992 monograph is essen\- tially two decades old, it does not cover multivariate generalizability theory in depth, and it does not incorporate recent developments in statistics that bear upon the estimation of variance components. Also, of course, there have been numerous developments in generalizability theory in the last 20 years.},
  file = {/Users/solomonkurz/Zotero/storage/PW8Z4E78/9780387952826.html},
  isbn = {978-0-387-95282-6},
  language = {en},
  series = {Statistics for {{Social}} and {{Behavioral Sciences}}}
}

@book{brms2020RM,
  title = {{{brms}} Reference Manual, {{Version}} 2.13.5},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms/brms.pdf}
}

@article{bryk1987application,
  title = {Application of Hierarchical Linear Models to Assessing Change.},
  author = {Bryk, Anthony S and Raudenbush, Stephen W},
  year = {1987},
  volume = {101},
  pages = {147},
  publisher = {{American Psychological Association}},
  doi = {10.1037/0033-2909.101.1.147},
  url = {https://personal.psu.edu/jxb14/M554/articles/Bryk\%26Raudenbush1987.pdf},
  journal = {Psychological bulletin},
  number = {1}
}

@article{Bürkner2020Parameterization,
  title = {Parameterization of Response Distributions in Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_families.html}
}

@article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian}} Multilevel Modeling with the {{R}} Package Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2018},
  volume = {10},
  pages = {395--411},
  doi = {10.32614/RJ-2018-017},
  journal = {The R Journal},
  number = {1}
}

@article{burknerBrmsPackageBayesian2017,
  title = {{{brms}}: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  volume = {80},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  journal = {Journal of Statistical Software},
  number = {1}
}

@misc{CausalInferenceStatistics,
  title = {Causal {{Inference}} in {{Statistics}}: {{A Primer}} | {{Wiley}}},
  shorttitle = {Causal {{Inference}} in {{Statistics}}},
  url = {https://www.wiley.com/en-us/Causal+Inference+in+Statistics\%3A+A+Primer-p-9781119186847},
  urldate = {2020-09-17},
  abstract = {Many of the concepts and terminology surrounding modern causal inference can be quite intimidating to the novice. Judea Pearl presents a book ideal for beginners in statistics, providing a comprehensive introduction to the field of causality. Examples from classical statistics are presented throughout to demonstrate the need for causality in resolving decision-making dilemmas posed by data. Causal methods are also compared to traditional statistical methods, whilst questions are provided at the end of each section to aid student learning.},
  file = {/Users/solomonkurz/Zotero/storage/BSESSITB/Causal+Inference+in+Statistics+A+Primer-p-9781119186847.html},
  journal = {Wiley.com},
  language = {en-us}
}

@article{chungNondegeneratePenalizedLikelihood2013,
  title = {A Nondegenerate Penalized Likelihood Estimator for Variance Parameters in Multilevel Models},
  author = {Chung, Yeojin and {Rabe-Hesketh}, Sophia and Dorie, Vincent and Gelman, Andrew and Liu, Jingchen},
  year = {2013},
  month = oct,
  volume = {78},
  pages = {685--709},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-013-9328-2},
  url = {http://link.springer.com/10.1007/s11336-013-9328-2},
  urldate = {2020-05-17},
  journal = {Psychometrika},
  language = {en},
  number = {4}
}

@article{cranfordProcedureEvaluatingSensitivity2006,
  title = {A Procedure for Evaluating Sensitivity to Within-Person Change: {{Can}} Mood Measures in Diary Studies Detect Change Reliably?},
  shorttitle = {A {{Procedure}} for {{Evaluating Sensitivity}} to {{Within}}-{{Person Change}}},
  author = {Cranford, James A. and Shrout, Patrick E. and Iida, Masumi and Rafaeli, Eshkol and Yip, Tiffany and Bolger, Niall},
  year = {2006},
  month = jul,
  volume = {32},
  pages = {917--929},
  publisher = {{SAGE Publications Inc}},
  issn = {0146-1672},
  doi = {10.1177/0146167206287721},
  url = {https://doi.org/10.1177/0146167206287721},
  urldate = {2020-09-17},
  abstract = {The recent growth in diary and experience sampling research has increased research attention on how people change over time in natural settings. Often however, the measures in these studies were originally developed for studying between-person differences, and their sensitivity to within-person changes is usually unknown. Using a Generalizability Theory framework, the authors illustrate a procedure for developing reliable measures of change using a version of the Profile of Mood States (POMS; McNair, Lorr, \& Droppleman, 1992) shortened for diary studies. Analyzing two data sets, one composed of 35 daily reports from 68 persons experiencing a stressful examination and another composed of daily reports from 164 persons over a typical 28-day period, we demonstrate that three-item measures of anxious mood, depressed mood, anger, fatigue, and vigor have appropriate reliability to detect within-person change processes.},
  file = {/Users/solomonkurz/Zotero/storage/FLCYL85F/Cranford et al. - 2006 - A Procedure for Evaluating Sensitivity to Within-P.pdf},
  journal = {Personality and Social Psychology Bulletin},
  language = {en},
  number = {7}
}

@book{cronbachDependabilityBehavioralMeasurements1972,
  title = {The Dependability of Behavioral Measurements: {{Theory}} of Generalizability for Scores and Profiles},
  shorttitle = {The {{Dependability}} of {{Behavioral Measurements}}},
  author = {Cronbach, Lee J. and Gleser, Goldine C. and Nanda, Harinder and Rajaratnam, Nageswari},
  year = {1972},
  month = jan,
  publisher = {{John Wiley \& Sons}},
  address = {{New York}},
  url = {https://www.amazon.com/Dependability-Behavioral-Measurements-Generalizability-Profiles/dp/0471188506},
  abstract = {The Dependability of Behavioral Measurements: Theory of Generalizability for Scores and Profiles [hardcover] Lee J. Cronbach,Goldine C. Gleser,Harinder Nanda,Nageswari Rajaratnam [Jun 14, 1972]},
  isbn = {978-0-471-18850-6},
  language = {English}
}

@article{gabry2019visualization,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  volume = {182},
  pages = {389--402},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/rssa.12378},
  url = {https://arxiv.org/abs/1709.01449},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  number = {2}
}

@book{gelman2013bayesian,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year = {2013},
  publisher = {{CRC press}},
  url = {https://stat.columbia.edu/~gelman/book/}
}

@book{gelmanDataAnalysisUsing2006,
  title = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
  author = {Gelman, Andrew and Hill, Jennifer},
  year = {2006},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511790942},
  url = {https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983},
  urldate = {2020-09-17},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
  file = {/Users/solomonkurz/Zotero/storage/KFY9IC96/32A29531C7FD730C3A68951A17C9D983.html},
  isbn = {978-0-521-86706-1},
  series = {Analytical {{Methods}} for {{Social Research}}}
}

@article{gelmanRsquaredBayesianRegression2019,
  title = {R-Squared for {{Bayesian}} Regression Models},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  year = {2019},
  month = jul,
  volume = {73},
  pages = {307--309},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2018.1549100},
  url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1549100},
  urldate = {2020-05-16},
  journal = {The American Statistician},
  language = {en},
  number = {3}
}

@book{gilksMCMCinPractice1995,
  title = {Markov Chain {{Monte Carlo}} in Practice},
  author = {Gilks, W.R. and Richardson, S. and Spiegelhalter, David},
  year = {1995},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://www.routledge.com/Markov-Chain-Monte-Carlo-in-Practice/Gilks-Richardson-Spiegelhalter/p/book/9780412055515},
  urldate = {2020-09-17},
  isbn = {978-0-412-05551-5},
  language = {English}
}

@article{jaegerR2StatisticFixed2017,
  title = {An {{R2}} Statistic for Fixed Effects in the Generalized Linear Mixed Model},
  author = {Jaeger, Byron C. and Edwards, Lloyd J. and Das, Kalyan and Sen, Pranab K.},
  year = {2017},
  month = apr,
  volume = {44},
  pages = {1086--1105},
  publisher = {{Taylor \& Francis}},
  issn = {0266-4763},
  doi = {10.1080/02664763.2016.1193725},
  url = {https://www.researchgate.net/publication/303887200_An_R_2_statistic_for_fixed_effects_in_the_generalized_linear_mixed_model},
  urldate = {2020-09-17},
  abstract = {Measuring the proportion of variance explained (R2) by a statistical model and the relative importance of specific predictors (semi-partial R2) can be essential considerations when building a parsimonious statistical model. The R2 statistic is a familiar summary of goodness-of-fit for normal linear models and has been extended in various ways to more general models. In particular, the generalized linear mixed model (GLMM) extends the normal linear model and is used to analyze correlated (hierarchical), non-normal data structures. Although various R2 statistics have been proposed, there is no consensus in statistical literature for the most sensible definition of R2 in this context. This research aims to build upon existing knowledge and definitions of R2 and to concisely define the statistic for the GLMM. Here, we derive a model and semi-partial R2 statistic for fixed (population) effects in the GLMM by utilizing the penalized quasi-likelihood estimation method based on linearization. We show that our proposed R2 statistic generalizes the widely used marginal R2 statistic introduced by Nakagawa and Schielzeth, demonstrate our statistics capability in model selection, show the utility of semi-partial R2 statistics in longitudinal data analysis, and provide software that computes the proposed R2 statistic along with semi-partial R2 for individual fixed effects. The software provided is adapted for both SAS and R programming languages.},
  annotation = {\_eprint: https://doi.org/10.1080/02664763.2016.1193725},
  file = {/Users/solomonkurz/Zotero/storage/82SECBMK/02664763.2016.html},
  journal = {Journal of Applied Statistics},
  keywords = {62-07,62Fxx,62Hxx,62Pxx,Blood pressure,clustered data,generalized linear mixed model,R-squared,statistical software},
  number = {6}
}

@book{kreftComparingFourDifferent1990,
  title = {Comparing Four Different Statistical Packages for Hierarchical Linear Regression: {{GENMOD}}, {{HLM}}, {{ML2}}, and {{VARCL}}},
  shorttitle = {Comparing {{Four Different Statistical Packages}} for {{Hierarchical Linear Regression}}},
  author = {Kreft, Ita G. G. and {de Leeuw}, Jan},
  year = {1990},
  month = feb,
  publisher = {{CSE Dissemination Office, UCLA Graduate School of Education, 405 Hilgard Avenue, Los Angeles, CA 90024-1521.}},
  url = {https://files.eric.ed.gov/fulltext/ED340731.pdf},
  urldate = {2020-09-17},
  abstract = {An overview is given of the available statistical theory and software for analyzing hierarchically nested data. Programs are evaluated, and general techniques are proposed to analyze data from several domains. This research is part of a larger project to evaluate elementary education in the Netherlands. The models discussed are the random coefficient models, the hierarchical mixed linear models, and the multilevel linear models. The abstract characteristics of the three classes of models and the systematic treatment of random and non-random parts of each class are described. Transformation of the models and the likelihood function are considered. The following four computer programs, using various types of algorithms, are discussed: (1) GENMOD; (2) HLM; (3) ML2; and (4) VARCL.  Each is compared for design, implementation, performance and results, and ease of use. To overcome some of the disadvantages of these techniques, a new program, MULTIPATH, is proposed for a more general approach to the analysis of data from different domains. Thirteen data tables and a 61-item list of references are included. (SLD)},
  file = {/Users/solomonkurz/Zotero/storage/R6QX9T5E/Kreft and And Others - 1990 - Comparing Four Different Statistical Packages for .pdf;/Users/solomonkurz/Zotero/storage/ES622HED/eric.ed.gov.html},
  keywords = {Comparative Analysis,Computer Software,Computer Software Evaluation,Educational Assessment,Elementary Education,Equations (Mathematics),Foreign Countries,Mathematical Models,Regression (Statistics)},
  language = {en}
}

@book{kreftIntroducingMultilevelModeling1998,
  title = {Introducing Multilevel Modeling},
  author = {Kreft, Ita G. and {de Leeuw}, Jan},
  year = {1998},
  publisher = {{SAGE Publications, Inc}},
  doi = {https://dx.doi.org/10.4135/9781849209366},
  url = {https://methods.sagepub.com/book/introducing-multilevel-modeling},
  urldate = {2020-09-17},
  isbn = {978-1-84920-936-6},
  language = {English}
}

@book{kruschkeDoingBayesianData2015,
  title = {Doing {{Bayesian}} Data Analysis: {{A}} Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John K.},
  year = {2015},
  publisher = {{Academic Press}},
  url = {https://sites.google.com/site/doingbayesiandataanalysis/}
}

@book{kurzStatisticalRethinkingBrms2020,
  title = {Statistical Rethinking with Brms, Ggplot2, and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = mar,
  edition = {version 1.1.0},
  doi = {10.5281/zenodo.3693202},
  url = {https://bookdown.org/content/3890/},
  urldate = {2020-05-16},
  abstract = {This project is an attempt to re-express the code in McElreath's textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/MTCXZRHZ/3890.html}
}

@book{kurzStatisticalRethinkingSecondEd2020,
  title = {Statistical Rethinking with Brms, Ggplot2, and the Tidyverse: {{Second}} Edition},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = jun,
  edition = {version 0.0.3},
  url = {https://bookdown.org/content/4857/},
  urldate = {2020-06-30},
  abstract = {This book is an attempt to re-express the code in the second edition of McElreath's textbook, 'Statistical rethinking.' His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.}
}

@book{lambertAStudentsGuidetoBayes2018,
  title = {A Student's Guide to {{Bayesian}} Statistics},
  author = {Lambert, Ben},
  year = {2018},
  publisher = {{SAGE Publications, Inc}},
  url = {https://ben-lambert.com/a-students-guide-to-bayesian-statistics/},
  urldate = {2020-09-17},
  isbn = {978-1-4739-1635-7},
  language = {English}
}

@article{liAdjustedMaximumLikelihood2010,
  title = {An Adjusted Maximum Likelihood Method for Solving Small Area Estimation Problems},
  author = {Li, Huilin and Lahiri, P.},
  year = {2010},
  month = apr,
  volume = {101},
  pages = {882--892},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2009.10.009},
  url = {http://www.sciencedirect.com/science/article/pii/S0047259X09002000},
  urldate = {2020-09-18},
  abstract = {For the well-known Fay\textendash Herriot small area model, standard variance component estimation methods frequently produce zero estimates of the strictly positive model variance. As a consequence, an empirical best linear unbiased predictor of a small area mean, commonly used in small area estimation, could reduce to a simple regression estimator, which typically has an overshrinking problem. We propose an adjusted maximum likelihood estimator of the model variance that maximizes an adjusted likelihood defined as a product of the model variance and a standard likelihood (e.g., a profile or residual likelihood) function. The adjustment factor was suggested earlier by Carl Morris in the context of approximating a hierarchical Bayes solution where the hyperparameters, including the model variance, are assumed to follow a prior distribution. Interestingly, the proposed adjustment does not affect the mean squared error property of the model variance estimator or the corresponding empirical best linear unbiased predictors of the small area means in a higher order asymptotic sense. However, as demonstrated in our simulation study, the proposed adjustment has a considerable advantage in small sample inference, especially in estimating the shrinkage parameters and in constructing the parametric bootstrap prediction intervals of the small area means, which require the use of a strictly positive consistent model variance estimate.},
  file = {/Users/solomonkurz/Zotero/storage/3V35792L/Li and Lahiri - 2010 - An adjusted maximum likelihood method for solving .pdf;/Users/solomonkurz/Zotero/storage/H5CZ5UBN/S0047259X09002000.html},
  journal = {Journal of Multivariate Analysis},
  keywords = {Adjusted density maximization estimator,Parametric bootstrap,Prediction intervals,The Fay–Herriot model},
  language = {en},
  number = {4}
}

@article{lopilatoUpdatingGeneralizabilityTheory2015,
  title = {Updating Generalizability Theory in Management Research: {{Bayesian}} Estimation of Variance Components},
  shorttitle = {Updating {{Generalizability Theory}} in {{Management Research}}},
  author = {LoPilato, Alexander C. and Carter, Nathan T. and Wang, Mo},
  year = {2015},
  month = feb,
  volume = {41},
  pages = {692--717},
  publisher = {{SAGE Publications Inc}},
  issn = {0149-2063},
  doi = {10.1177/0149206314554215},
  url = {https://doi.org/10.1177/0149206314554215},
  urldate = {2020-09-17},
  abstract = {In the management literature, generalizability theory (GT) has been typically used to investigate the reliability of assessment center and job performance ratings. However, the management field has yet to take full advantage of the information GT can offer regarding the reliability of measurement. It is likely that GT has not been adopted because of the complexities involved with its notation and practical application. Moreover, current methods for obtaining accurate interval estimates around estimated variance components or their reliability coefficients are not easily implementable. Alternatively, Bayesian methods provide a different method for estimating GT variance components. Bayesian methods enable management researchers to estimate the posterior distributions of each GT variance component as well as the GT reliability coefficients. From these posterior distributions, researchers can easily obtain the interval estimates for each variance component and the corresponding reliability estimates. Conducting two studies, the authors examine what priors should be used when conducting a Bayesian GT analysis and what estimates should be used to summarize a variance component's posterior distribution. Additionally, the authors find that under certain conditions, Bayesian methods perform better than frequentist methods.},
  journal = {Journal of Management},
  language = {en},
  number = {2}
}

@book{MASS2002,
  title = {Modern Applied Statistics with {{S}}},
  author = {Venables, W. N. and Ripley, B. D.},
  year = {2002},
  edition = {Fourth},
  publisher = {{Springer}},
  address = {{New York}},
  url = {http://www.stats.ox.ac.uk/pub/MASS4}
}

@book{mcelreathStatisticalRethinkingBayesian2015,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  year = {2015},
  publisher = {{CRC press}},
  url = {https://xcelab.net/rm/statistical-rethinking/}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  edition = {Second edition},
  publisher = {{CRC Press}},
  url = {https://xcelab.net/rm/statistical-rethinking/},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on GitHub},
  isbn = {978-0-429-63914-2},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {en}
}

@book{millerBeyondANOVA1997,
  title = {Beyond {{ANOVA}}: {{Basics}} of Applied Statistics},
  author = {Rupert G. Miller, Jr.},
  year = {1997},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://www.routledge.com/Beyond-ANOVA-Basics-of-Applied-Statistics/Jr/p/book/9780412070112},
  urldate = {2020-09-17},
  isbn = {978-0-412-07011-2},
  language = {English}
}

@article{morrisEstimatingRandomEffects2011,
  title = {Estimating {{Random Effects}} via {{Adjustment}} for {{Density Maximization}}},
  author = {Morris, Carl and Tang, Ruoxi},
  year = {2011},
  month = may,
  volume = {26},
  pages = {271--287},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/10-STS349},
  url = {https://projecteuclid.org/euclid.ss/1312204020},
  urldate = {2020-09-18},
  abstract = {We develop and evaluate point and interval estimates for the random effects \texttheta i, having made observations yi|\texttheta i {$\sim$}ind N[\texttheta i, Vi], i = 1, \ldots, k that follow a two-level Normal hierarchical model. Fitting this model requires assessing the Level-2 variance A {$\equiv$} Var(\texttheta i) to estimate shrinkages Bi {$\equiv$} Vi\,/\,(Vi + A) toward a (possibly estimated) subspace, with Bi as the target because the conditional means and variances of \texttheta i depend linearly on Bi, not on A. Adjustment for density maximization, ADM, can do the fitting for any smooth prior on A. Like the MLE, ADM bases inferences on two derivatives, but ADM can approximate with any Pearson family, with Beta distributions being appropriate because shrinkage factors satisfy 0 {$\leq$} Bi {$\leq$} 1. Our emphasis is on frequency properties, which leads to adopting a uniform prior on A {$\geq$} 0, which then puts Stein's harmonic prior (SHP) on the k random effects. It is known for the ``equal variances case'' V1 = {$\cdots$} = Vk that formal Bayes procedures for this prior produce admissible minimax estimates of the random effects, and that the posterior variances are large enough to provide confidence intervals that meet their nominal coverages. Similar results are seen to hold for our approximating ``ADM-SHP'' procedure for equal variances and also for the unequal variances situations checked here. For shrinkage coefficient estimation, the ADM-SHP procedure allows an alternative frequency interpretation. Writing L(A) as the likelihood of Bi with i fixed, ADM-SHP estimates Bi as {\^B}i = Vi\,/\,(Vi + \^A) with \^A {$\equiv$} argmax\,(A {${_\ast}$} L(A)). This justifies the term ``adjustment for likelihood maximization,'' ALM.},
  file = {/Users/solomonkurz/Zotero/storage/DAGXMQSL/Morris and Tang - 2011 - Estimating Random Effects via Adjustment for Densi.pdf;/Users/solomonkurz/Zotero/storage/UQ4M9CVV/1312204020.html},
  journal = {Statistical Science},
  keywords = {ADM,Normal multilevel model,objective Bayes,Shrinkage,Stein estimation},
  language = {EN},
  mrnumber = {MR2858514},
  number = {2},
  zmnumber = {1246.62025}
}

@book{newsom2015longitudinal,
  title = {Longitudinal Structural Equation Modeling: {{A}} Comprehensive Introduction},
  author = {Newsom, Jason T},
  year = {2015},
  publisher = {{Routledge}},
  url = {http://www.longitudinalsem.com/},
  isbn = {978-1-84872-697-0}
}

@article{nezlekMultilevelFrameworkUnderstanding2007,
  title = {A Multilevel Framework for Understanding Relationships among Traits, States, Situations and Behaviours},
  author = {Nezlek, John B.},
  year = {2007},
  volume = {21},
  pages = {789--810},
  issn = {1099-0984},
  doi = {10.1002/per.640},
  url = {https://www.researchgate.net/publication/228079300_A_Multilevel_Framework_for_Understanding_Relationships_Among_Traits_States_Situations_and_Behaviours},
  urldate = {2020-09-17},
  abstract = {A conceptual and analytic framework for understanding relationships among traits, states, situations, and behaviours is presented. The framework assumes that such relationships can be understood in terms of four questions. (1) What are the relationships between trait and state level constructs, which include psychological states, the situations people experience and behaviour? (2) What are the relationships between psychological states, between states and situations and between states and behaviours? (3) How do such state level relationships vary as a function of trait level individual differences? (4) How do the relationships that are the focus of questions 1, 2, and 3 change across time? This article describes how to use multilevel random coefficient modelling (MRCM) to examine such relationships. The framework can accommodate different definitions of traits and dispositions (Allportian, processing styles, profiles, etc.) and different ways of conceptualising relationships between states and traits (aggregationist, interactionist, etc.). Copyright \textcopyright{} 2007 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/per.640},
  copyright = {Copyright \textcopyright{} 2007 John Wiley \& Sons, Ltd.},
  file = {/Users/solomonkurz/Zotero/storage/E2MM722N/per.html},
  journal = {European Journal of Personality},
  keywords = {methods,multilevel analysis,statistical methods,traits},
  language = {en},
  number = {6}
}

@article{nosekPreregistrationRevolution2018,
  title = {The Preregistration Revolution},
  author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
  year = {2018},
  month = mar,
  volume = {115},
  pages = {2600--2606},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1708274114},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1708274114},
  urldate = {2020-09-17},
  abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes\textemdash a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
  file = {/Users/solomonkurz/Zotero/storage/BCF88LAV/Nosek et al. - 2018 - The preregistration revolution.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {11}
}

@book{pearlCausalInferenceStatistics2016,
  title = {Causal {{Inference}} in {{Statistics}} - {{A Primer}}},
  author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
  year = {2016},
  month = mar,
  edition = {1st Edition},
  publisher = {{Wiley}},
  address = {{Chichester, West Sussex}},
  url = {https://www.wiley.com/en-us/Causal+Inference+in+Statistics\%3A+A+Primer-p-9781119186847},
  abstract = {Many of the concepts and terminology surrounding modern causal inference can be quite intimidating to the novice. Judea Pearl presents a book ideal for beginners in statistics, providing a comprehensive introduction to the field of causality.~ Examples from classical statistics are presented throughout to demonstrate the need for causality in resolving decision-making dilemmas posed by data. Causal methods are also compared to traditional statistical methods, whilst questions are provided at the end of each section to aid student learning.},
  isbn = {978-1-119-18684-7},
  language = {English}
}

@book{pengProgrammingDataScience2019,
  title = {R Programming for Data Science},
  author = {Peng, Roger D.},
  year = {2019},
  url = {https://bookdown.org/rdpeng/rprogdatascience/}
}

@inproceedings{plummer2003jags,
  title = {{{JAGS}}: {{A}} Program for Analysis of {{Bayesian}} Graphical Models Using {{Gibbs}} Sampling},
  booktitle = {Proceedings of the 3rd International Workshop on Distributed Statistical Computing},
  author = {Plummer, Martyn},
  year = {2003},
  volume = {124},
  pages = {1--10},
  url = {http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Drafts/Plummer.pdf},
  organization = {{Vienna, Austria}}
}

@book{plummer2012jags,
  title = {{{JAGS Version}} 3.3.0 User Manual},
  author = {Plummer, Martyn},
  year = {2012},
  url = {http://www.stat.cmu.edu/~brian/463-663/week10/articles,\%20manuals/jags_user_manual.pdf}
}

@book{R-base,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}},
  url = {https://www.R-project.org/}
}

@book{R-bayesplot,
  title = {{{bayesplot}}: {{Plotting}} for {{Bayesian}} Models},
  author = {Gabry, Jonah and Mahr, Tristan},
  year = {2019},
  url = {https://CRAN.R-project.org/package=bayesplot}
}

@book{R-brms,
  title = {{{brms}}: {{Bayesian}} Regression Models Using '{{Stan}}'},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms}
}

@manual{R-broom,
  title = {Broom: {{Convert}} Statistical Analysis Objects into Tidy Tibbles},
  author = {Robinson, David and Hayes, Alex},
  year = {2020},
  url = {https://CRAN.R-project.org/package=broom},
  type = {Manual}
}

@manual{R-corrr,
  title = {{{corrr}}: {{Correlations}} in {{R}}},
  author = {Kuhn, Max and Jackson, Simon and Cimentada, Jorge},
  year = {2020},
  url = {https://CRAN.R-project.org/package=corrr},
  type = {Manual}
}

@book{R-lme4,
  title = {{{lme4}}: {{Linear}} Mixed-Effects Models Using {{Eigen}}' and {{S4}}},
  author = {Bates, Douglas and Maechler, Martin and Bolker, Ben and Walker, Steven},
  year = {2020},
  url = {https://CRAN.R-project.org/package=lme4}
}

@book{R-loo,
  title = {{{loo}}: {{Efficient}} Leave-One-out Cross-Validation and {{WAIC}} for Bayesian Models},
  author = {Vehtari, Aki and Gabry, Jonah and Magnusson, Mans and Yao, Yuling and Gelman, Andrew},
  year = {2019},
  url = {https://CRAN.R-project.org/package=loo}
}

@book{R-MASS,
  title = {{{MASS}}: {{Support}} Functions and Datasets for Venables and Ripley's {{MASS}}},
  author = {Ripley, Brian},
  year = {2019},
  url = {https://CRAN.R-project.org/package=MASS}
}

@book{R-metRology,
  title = {{{metRology}}: {{Support}} for Metrological Applications},
  author = {Ellison., Stephen L R},
  year = {2018},
  url = {https://CRAN.R-project.org/package=metRology}
}

@book{R-patchwork,
  title = {{{patchwork}}: {{The}} Composer of Plots},
  author = {Pedersen, Thomas Lin},
  year = {2019},
  url = {https://CRAN.R-project.org/package=patchwork}
}

@book{R-posterior,
  title = {{{posterior}}: {{Tools}} for Working with Posterior Distributions},
  author = {B{\"u}rkner, Paul-Christian and Gabry, Jonah and Kay, Matthew and Vehtari, Aki},
  year = {2020},
  url = {https://mc-stan.org/posterior}
}

@book{R-psych,
  title = {{{psych}}: {{Procedures}} for Psychological, Psychometric, and Personality Research},
  author = {Revelle, William},
  year = {2020},
  url = {https://CRAN.R-project.org/package=psych}
}

@book{R-rethinking,
  title = {{{rethinking}} {{R}} Package},
  author = {McElreath, Richard},
  year = {2020},
  url = {https://xcelab.net/rm/software/}
}

@book{R-tidybayes,
  title = {{{tidybayes}}: {{Tidy}} Data and 'geoms' for {{Bayesian}} Models},
  author = {Kay, Matthew},
  year = {2020},
  url = {http://mjskay.github.io/tidybayes}
}

@book{R-tidyverse,
  title = {{{tidyverse}}: {{Easily}} Install and Load the 'Tidyverse'},
  author = {Wickham, Hadley},
  year = {2019},
  url = {https://CRAN.R-project.org/package=tidyverse}
}

@article{raudenbushGrowthCurveAnalysis2016,
  title = {Growth {{Curve Analysis}} in {{Accelerated Longitudinal Designs}}:},
  shorttitle = {Growth {{Curve Analysis}} in {{Accelerated Longitudinal Designs}}},
  author = {Raudenbush, Stephen W. and Chan, Wing-Shing},
  year = {2016},
  month = aug,
  publisher = {{SAGE PUBLICATIONS}},
  doi = {10.1177/0022427892029004001},
  url = {https://journals.sagepub.com/doi/10.1177/0022427892029004001},
  urldate = {2020-09-17},
  abstract = {Accelerated longitudinal designs enable researchers to study individual development over a long interval of the life course by gathering data during a comparati...},
  file = {/Users/solomonkurz/Zotero/storage/N4AMTUFZ/0022427892029004001.html},
  journal = {Journal of Research in Crime and Delinquency},
  language = {en}
}

@book{raudenbushHLM2002,
  title = {Hierarchical Linear Models: {{Applications}} and Data Analysis Methods},
  author = {Raudenbush, Stephen W. and Bryk, Anthony S.},
  year = {2002},
  edition = {Second},
  publisher = {{SAGE Publications, Inc}},
  url = {https://us.sagepub.com/en-us/nam/hierarchical-linear-models/book9230},
  urldate = {2020-09-17},
  isbn = {978-0-7619-1904-9},
  language = {English}
}

@article{rightsEffectSizeMeasures2018,
  title = {Effect Size Measures for Multilevel Models in Clinical Child and Adolescent Research: {{New}} {{R}}-Squared Methods and Recommendations},
  shorttitle = {Effect {{Size Measures}} for {{Multilevel Models}} in {{Clinical Child}} and {{Adolescent Research}}},
  author = {Rights, Jason D. and Cole, David A.},
  year = {2018},
  month = nov,
  volume = {47},
  pages = {863--873},
  publisher = {{Routledge}},
  issn = {1537-4416},
  doi = {10.1080/15374416.2018.1528550},
  url = {https://www.tandfonline.com/doi/abs/10.1080/15374416.2018.1528550},
  urldate = {2020-09-17},
  abstract = {Clinical psychologists studying child and adolescent populations commonly analyze hierarchically structured data via multilevel modeling (MLM). In clinical child and adolescent psychology, and in psychology more broadly, increasing emphasis is being placed on the reporting of effect size, such as R-squared (R2) measures of explained variance. In MLM, however, the literature on R2 had, until recently, suffered from several shortcomings: (a) the relations among existing measures were unknown, (b) methods for quantifying some types of explained variance were unavailable, (c) which (if any) measures should be used for model comparison was unclear, (d) most measures did not generalize to models with more than two levels, and (e) software to compute measures was unavailable. The purpose of this article is to summarize recent methodological developments that resolved these issues and encourage the use of MLM R2 in practice. We provide a nontechnical discussion of how the issues have been resolved and demonstrate how the new measures and methods can be implemented, highlighting their utility with an empirical example. We first consider a two-level MLM for a single hypothesized model in which we examine emotional response to social situations as a predictor of maladaptive self-cognitions, demonstrating the various ways we can quantify explained variance. We then discuss and demonstrate the use of R2 for model comparison, and discuss the extension to models with more than two levels. Last, we discuss new free software that researchers can use to compute measures and produce associated graphics.},
  annotation = {\_eprint: https://doi.org/10.1080/15374416.2018.1528550},
  file = {/Users/solomonkurz/Zotero/storage/PN5F7E5G/15374416.2018.html},
  journal = {Journal of Clinical Child \& Adolescent Psychology},
  number = {6},
  pmid = {30433818}
}

@article{rightsNewRecommendationsUse2019,
  title = {New Recommendations on the Use of {{R}}-Squared Differences in Multilevel Model Comparisons},
  author = {Rights, Jason D. and Sterba, Sonya K.},
  year = {2019},
  month = sep,
  volume = {0},
  pages = {1--32},
  publisher = {{Routledge}},
  issn = {0027-3171},
  doi = {10.1080/00273171.2019.1660605},
  url = {https://www.researchgate.net/publication/336105908_New_Recommendations_on_the_Use_of_R-Squared_Differences_in_Multilevel_Model_Comparisons},
  urldate = {2020-09-17},
  abstract = {When comparing multilevel models (MLMs) differing in fixed and/or random effects, researchers have had continuing interest in using R-squared differences to communicate effect size and importance of included terms. However, there has been longstanding confusion regarding which R-squared difference measures should be used for which kind of MLM comparisons. Furthermore, several limitations of recent studies on R-squared differences in MLM have led to misleading or incomplete recommendations for practice. These limitations include computing measures that are by definition incapable of detecting a particular type of added term, considering only a subset of the broader class of available R-squared difference measures, and incorrectly defining what a given R-squared difference measure quantifies. The purpose of this paper is to elucidate and resolve these issues. To do so, we define a more general set of total, within-cluster, and between-cluster R-squared difference measures than previously considered in MLM comparisons and give researchers concrete step-by-step procedures for identifying which measure is relevant to which model comparison. We supply simulated and analytic demonstrations of limitations of previous MLM studies on R-squared differences and show how application of our step-by-step procedures and general set of measures overcomes each. Additionally, we provide and illustrate graphical tools and software allowing researchers to automatically compute and visualize our set of measures in an integrated manner. We conclude with recommendations, as well as extensions involving (a) how our framework relates to and can be used to obtain pseudo-R-squareds, and (b) how our framework can accommodate both simultaneous and hierarchical model-building approaches.},
  annotation = {\_eprint: https://doi.org/10.1080/00273171.2019.1660605},
  file = {/Users/solomonkurz/Zotero/storage/YAH9FUNR/00273171.2019.html},
  journal = {Multivariate Behavioral Research},
  keywords = {effect size,explained variance,hierarchical linear models,mixed effects models,model comparison,Multilevel modeling,R-squared},
  number = {0},
  pmid = {31559890}
}

@article{rogosaGrowthCurveApproach1982,
  title = {A Growth Curve Approach to the Measurement of Change},
  author = {Rogosa, David and Brandt, David and Zimowski, Michele},
  year = {1982},
  volume = {92},
  pages = {726--748},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1455(Electronic),0033-2909(Print)},
  doi = {10.1037/0033-2909.92.3.726},
  url = {https://www.researchgate.net/publication/232478172_A_Growth_Curve_Approach_to_the_Measurement_of_Change},
  abstract = {The measurement of individual change is approached from the standpoint of individual time paths and statistical models for individual change. The authors consider both statistical and psychometric properties of measures of individual change and examine measures of change for data with more than 2 observations on each individual. It is noted that many conclusions conflict with previous behavioral science literature. (63 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/LVXIKC9M/1983-04708-001.html},
  journal = {Psychological Bulletin},
  keywords = {Behavior Change,Psychometrics,Statistical Analysis},
  number = {3}
}

@article{rogosaUnderstandingCorrelatesChange1985,
  title = {Understanding Correlates of Change by Modeling Individual Differences in Growth},
  author = {Rogosa, David R. and Willett, John B.},
  year = {1985},
  month = jun,
  volume = {50},
  pages = {203--228},
  issn = {1860-0980},
  doi = {10.1007/BF02294247},
  url = {https://gseacademic.harvard.edu/~willetjo/pdf\%20files/Rogosa\%20\&\%20Willett\%201985.pdf},
  urldate = {2020-09-17},
  abstract = {The study of correlates of change is the investigation of systematic individual differences in growth. Our representation of systematic individual differences in growth is built up in two parts: (a) a model for individual growth and, (b) a model for the dependence of parameters in the individual growth models on individual characteristics. First, explicit representations of correlates of change are constructed for various models of individual growth. Second, for the special case of initial status as a correlate of change, properties of collections of growth curves provide new results on the relation between change and initial status. Third, the shortcomings of previous approaches to the assessment of correlates of change are demonstrated. In particular, correlations of residual change measures with exogenous individual characteristics are shown to be poor indicators of systematic individual differences in growth.},
  journal = {Psychometrika},
  language = {en},
  number = {2}
}

@incollection{shroutPsychometrics2012,
  title = {Psychometrics},
  booktitle = {Handbook of Research Methods for Studying Daily Life},
  author = {Shrout, Patrick E. and Lane, Sean P.},
  year = {2012},
  pages = {302--320},
  publisher = {{The Guilford Press}},
  address = {{New York, NY, US}},
  abstract = {A basic provision of good research design is that measures should have good psychometric properties; that is, the measures should reflect the constructs of scientific interest and have minimal measurement error. Psychometric texts (e.g., Crocker \& Algina, 1986; Embretson \& Reise, 2000) instruct researchers on how to achieve these goals for single time point individual-difference measures, but rarely is attention paid to the psychometrics of intensive repeated measures, such as those obtained in diary studies. In this chapter we aim to provide guidelines and techniques for this special measurement context. Our focus is on the classic psychometric concepts of reliability and validity. We say that a measure is reliable when repeated applications of the measurement procedure produce the same numerical value. We say that a measure has validity if there is evidence that scores from the measurement procedure display empirical patterns that are consistent with the theoretical construct of interest. Reliability is necessary but not sufficient for validity (e.g., Shrout \& Lane, in press). It is possible to obtain a highly reliable measure that is not at all related to the construct for which it is named. We begin the chapter with a brief review of some of the special characteristics of diary studies that affect measurement quality. We then consider issues of reliability for diary data, noting that different definitions of reliability need to be used for between-person comparisons and within-person questions. Following our practical description of how to estimate reliability in diary studies, we consider issues of documenting the validity of diary measures. Throughout the chapter we illustrate the points with a numerical example based on an actual diary study. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/MAHLP6R3/2012-05165-017.html},
  isbn = {978-1-60918-747-7 978-1-60918-749-1},
  keywords = {Experimental Design,Experimental Psychologists,Experimentation,Journal Writing,Psychometrics,Test Reliability,Test Validity}
}

@book{singerAppliedLongitudinalData2003,
  title = {Applied Longitudinal Data Analysis: {{Modeling}} Change and Event Occurrence},
  shorttitle = {Applied Longitudinal Data Analysis},
  author = {Singer, Judith D. and Willett, John B.},
  year = {2003},
  month = mar,
  publisher = {{Oxford University Press, USA}},
  url = {https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968},
  abstract = {Change is constant in everyday life. Infants crawl and then walk, children learn to read and write, teenagers mature in myriad ways, the elderly become frail and forgetful. Beyond these natural processes and events, external forces and interventions instigate and disrupt change: test scores may rise after a coaching course, drug abusers may remain abstinent after residential treatment. By charting changes over time and investigating whether and when events occur, researchers reveal the temporal rhythms of our lives. Applied Longitudinal Data Analysis is a much-needed professional book for empirical researchers and graduate students in the behavioral, social, and biomedical sciences. It offers the first accessible in-depth presentation of two of today's most popular statistical methods: multilevel models for individual change and hazard/survival models for event occurrence (in both discrete- and continuous-time). Using clear, concise prose and real data sets from published studies, the authors take you step by step through complete analyses, from simple exploratory displays that reveal underlying patterns through sophisticated specifications of complex statistical models.Applied Longitudinal Data Analysis offers readers a private consultation session with internationally recognized experts and represents a unique contribution to the literature on quantitative empirical methods.Visit http://www.ats.ucla.edu/stat/examples/alda.htm for:DT Downloadable data setsDT Library of computer programs in SAS, SPSS, Stata, HLM, MLwiN, and moreDT Additional material for data analysis},
  googlebooks = {PpnA1M8VwR8C},
  isbn = {978-0-19-515296-8},
  keywords = {Mathematics / Probability \& Statistics / General,Medical / Epidemiology,Psychology / Statistics},
  language = {en}
}

@article{snijdersModeledVarianceTwolevel1994,
  title = {Modeled Variance in Two-Level Models},
  author = {Snijders, Tom A. B. and Bosker, Roel J.},
  year = {1994},
  month = feb,
  volume = {22},
  pages = {342--363},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124194022003004},
  url = {https://www.researchgate.net/publication/235726240_Modeled_Variance_in_Two-Level_Models},
  urldate = {2020-09-17},
  abstract = {The concept of explained proportion of variance or modeled proportion of variance is reviewed in the situation of the random effects hierarchical two-level model. It is argued that the proportional reduction in (estimated) variance components is not an attractive parameter to represent the joint importance of the explanatory (independent) variables for modeling the dependent variable. It is preferable instead to work with the proportional reduction in mean squared prediction error for predicting individual values (for the modeled variance at level 1) and the proportional reduction in mean squared prediction error for predicting group averages (for the modeled variance at level 2). It is shown that when predictors are added, the proportion of modeled variance defined in this way cannot go down in the population if the model is correctly specified, but can go down in a sample; the latter situation then points to the possibility of misspecification. This provides a diagnostic means for identifying misspecification.},
  journal = {Sociological Methods \& Research},
  language = {en},
  number = {3}
}

@article{spiegelhalterBayesianMeasuresModel2002,
  title = {Bayesian Measures of Model Complexity and Fit},
  author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and Linde, Angelika Van Der},
  year = {2002},
  volume = {64},
  pages = {583--639},
  issn = {1467-9868},
  doi = {10.1111/1467-9868.00353},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00353},
  urldate = {2020-06-12},
  abstract = {Summary. We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure pD for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general pD approximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the `hat' matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding pD to the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9868.00353},
  file = {/Users/solomonkurz/Zotero/storage/GGPTKT9M/Spiegelhalter et al. - 2002 - Bayesian measures of model complexity and fit.pdf;/Users/solomonkurz/Zotero/storage/SD8PUJGW/1467-9868.html},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {Bayesian model comparison,Decision theory,Deviance information criterion,Effective number of parameters,Hierarchical models,Information theory,Leverage,Markov chain Monte Carlo methods,Model dimension},
  language = {en},
  number = {4}
}

@article{spiegelhalterDevianceInformationCriterion2014,
  title = {The Deviance Information Criterion: 12 Years On},
  shorttitle = {The Deviance Information Criterion},
  author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and {van der Linde}, Angelika},
  year = {2014},
  volume = {76},
  pages = {485--493},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {1369-7412},
  url = {https://www.jstor.org/stable/24774528},
  urldate = {2020-09-17},
  abstract = {The essentials of our paper of 2002 are briefly summarized and compared with other criteria for model comparison. After some comments on the paper's reception and influence, we consider criticisms and proposals for improvement made by us and others.},
  journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
  number = {3}
}

@book{standevelopmentteamStanReferenceManual2020,
  title = {Stan Reference Manual, {{Version}} 2.24},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_24/reference-manual/}
}

@book{standevelopmentteamStanUserGuide2020,
  title = {Stan User's Guide, {{Version}} 2.24},
  author = {{Stan Development Team}},
  year = {2020},
  url = {https://mc-stan.org/docs/2_24/stan-users-guide/index.html}
}

@article{steegen2016increasing,
  title = {Increasing Transparency through a Multiverse Analysis},
  author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
  year = {2016},
  volume = {11},
  pages = {702--712},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  doi = {10.1177/1745691616658637},
  url = {https://journals.sagepub.com/doi/pdf/10.1177/1745691616658637},
  journal = {Perspectives on Psychological Science},
  number = {5}
}

@article{steegenIncreasingTransparencyMultiverse2016,
  title = {Increasing {{Transparency Through}} a {{Multiverse Analysis}}:},
  shorttitle = {Increasing {{Transparency Through}} a {{Multiverse Analysis}}},
  author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
  year = {2016},
  month = sep,
  publisher = {{SAGE PublicationsSage CA: Los Angeles, CA}},
  doi = {10.1177/1745691616658637},
  url = {https://journals.sagepub.com/doi/10.1177/1745691616658637},
  urldate = {2020-09-17},
  abstract = {Empirical research inevitably includes constructing a data set by processing raw data into a form ready for statistical analysis. Data processing often involves...},
  copyright = {\textcopyright{} The Author(s) 2016},
  file = {/Users/solomonkurz/Zotero/storage/HZIF4LZ2/Steegen et al. - 2016 - Increasing Transparency Through a Multiverse Analy.pdf;/Users/solomonkurz/Zotero/storage/922L4QCP/1745691616658637.html},
  journal = {Perspectives on Psychological Science},
  language = {en}
}

@article{vehtariPracticalBayesianModel2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  volume = {27},
  pages = {1413--1432},
  issn = {1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  url = {https://arxiv.org/pdf/1507.04544.pdf},
  urldate = {2020-06-03},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  file = {/Users/solomonkurz/Zotero/storage/I7HY567V/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf},
  journal = {Statistics and Computing},
  language = {en},
  number = {5}
}

@article{watanabeAsymptoticEquivalenceBayes2010,
  title = {Asymptotic Equivalence of {{Bayes}} Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory},
  author = {Watanabe, Sumio},
  year = {2010},
  volume = {11},
  pages = {3571--3594},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v11/watanabe10a.html},
  urldate = {2020-06-12},
  file = {/Users/solomonkurz/Zotero/storage/4HA4VYLM/Watanabe - 2010 - Asymptotic Equivalence of Bayes Cross Validation a.pdf;/Users/solomonkurz/Zotero/storage/MSKBHX5F/watanabe10a.html},
  journal = {Journal of Machine Learning Research},
  number = {116}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the Tidyverse},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  volume = {4},
  pages = {1686},
  doi = {10.21105/joss.01686},
  journal = {Journal of Open Source Software},
  number = {43}
}

@article{willettResultsReliabilityLongitudinal1989,
  title = {Some Results on Reliability for the Longitudinal Measurement of Change: {{Implications}} for the Design of Studies of Individual Growth},
  shorttitle = {Some {{Results}} on {{Reliability}} for the {{Longitudinal Measurement}} of {{Change}}},
  author = {Willett, John B.},
  year = {1989},
  month = sep,
  volume = {49},
  pages = {587--602},
  publisher = {{SAGE Publications Inc}},
  issn = {0013-1644},
  doi = {10.1177/001316448904900309},
  url = {https://doi.org/10.1177/001316448904900309},
  urldate = {2020-09-17},
  abstract = {When changes in educational or psychological status are being measured, every subject in the sample must be observed on several chronologically successive occasions. In the pursuit of such longitudinal data, traditional researchers have been content to administer only a pre-test and a post-test (thus collecting two waves of data on each subject). More recently, however, methodologists have argued that multiwave data (i.e., more than two waves) must be collected for the effective measurement of change. Multi-wave data allows a suitable mathematical model to be fitted to each of the individual growth records as a way of summarizing the growth of each subject. Subsequent investigations of between-individual differences in growth can then be based on the results of these fits.In this article, individual growth-modeling permits the reliability of change measurement to be examined. This reliability is shown to depend upon three factors: the magnitude of the inter-individual heterogeneity in true growth, the size of the measurement-error variance, and the number of waves of data that have been collected. The paper demonstrates that dramatic increases in the reliability of change measurement can be achieved by collecting relatively few additional waves of data, a finding that has considerable import for the informed design of longitudinal studies of individual change.},
  journal = {Educational and Psychological Measurement},
  language = {en},
  number = {3}
}

@article{williamsSurfaceUnearthingWithinperson2019,
  title = {Beneath the Surface: {{Unearthing}} within-{{Person}} Variability and Mean Relations with {{Bayesian}} Mixed Models},
  shorttitle = {Beneath the {{Surface}}},
  author = {Williams, Donald R. and Rouder, Jeffrey and Rast, Philippe},
  year = {2019},
  month = jun,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/gwatq},
  url = {https://osf.io/gwatq},
  urldate = {2020-08-05},
  abstract = {Mixed-effects models are becoming common in psychological science. Although they have many desirable features, there is still untapped potential that has not yet been fully realized. It is customary to view homogeneous variance as an assumption to satisfy. We argue to move beyond that perspective, and to view modeling within-person variance (``noise'') as an opportunity to gain a richer understanding of psychological processes. This can provide important insights into behavioral (in)stability. The technique to do so is based on the mixed-effects location scale model. The formulation can simultaneously estimate mixed-effects sub-models to both the mean (location) and within-person variance (scale) for clustered data common to psychology. We develop a framework that goes beyond assessing the sub-models in isolation of one another, and allows for testing structural relations between the mean and within-person variance with the Bayes factor. We first present a motivating example, which makes clear how the model can characterize mean\textendash variance relations. We then apply the method to reaction times gathered from two cognitive inference tasks. We find there are more individual differences in the within-person variance than the mean structure, as well as a complex web of structural mean\textendash variance relations in the random effects. This stands in contrast to the dominant view of within-person variance\textendash i.e., measurement ``error'' or ``noise.'' The results also point towards paradoxical within-person, as opposed to between-person, effects. That is, in both tasks, several people had \textbackslash emph\{slower\} and \textbackslash emph\{less\} variable incongruent responses. This contradicts the typical pattern, wherein \textbackslash emph\{larger\} means are expected to be \textbackslash emph\{more\} variable. We conclude with future directions. These span from methodological to theoretical inquires that can be answered with the presented methodology.}
}

@article{yaoUsingStackingAverage2018,
  title = {Using Stacking to Average {{Bayesian}} Predictive Distributions (with Discussion)},
  author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew and others},
  year = {2018},
  volume = {13},
  pages = {917--1007},
  publisher = {{International Society for Bayesian Analysis}},
  doi = {10.1214/17-BA1091},
  url = {https://projecteuclid.org/download/pdfview_1/euclid.ba/1516093227},
  journal = {Bayesian Analysis},
  number = {3}
}


