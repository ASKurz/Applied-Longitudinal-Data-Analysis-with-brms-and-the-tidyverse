
@article{aalen1988heterogeneity,
  title = {Heterogeneity in Survival Analysis},
  author = {Aalen, Odd O},
  year = {1988},
  volume = {7},
  pages = {1121--1137},
  publisher = {{Wiley Online Library}},
  doi = {10.1002/sim.4780071105},
  journal = {Statistics in medicine},
  number = {11}
}

@book{agrestiFoundationsLinearGeneralized2015,
  title = {Foundations of Linear and Generalized Linear Models},
  author = {Agresti, Alan},
  year = {2015},
  month = jan,
  publisher = {{John Wiley \& Sons}},
  url = {https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034},
  abstract = {A valuable overview of the most important ideas and results in statistical modeling Written by a highly-experienced author, Foundations of Linear and Generalized Linear Models is a clear and comprehensive guide to the key concepts and results of linearstatistical models. The book presents a broad, in-depth overview of the most commonly usedstatistical models by discussing the theory underlying the models, R software applications,and examples with crafted models to elucidate key ideas and promote practical modelbuilding. The book begins by illustrating the fundamentals of linear models, such as how the model-fitting projects the data onto a model vector subspace and how orthogonal decompositions of the data yield information about the effects of explanatory variables. Subsequently, the book covers the most popular generalized linear models, which include binomial and multinomial logistic regression for categorical data, and Poisson and negative binomial loglinear models for count data. Focusing on the theoretical underpinnings of these models, Foundations ofLinear and Generalized Linear Models also features:  An introduction to quasi-likelihood methods that require weaker distributional assumptions, such as generalized estimating equation methods An overview of linear mixed models and generalized linear mixed models with random effects for clustered correlated data, Bayesian modeling, and extensions to handle problematic cases such as high dimensional problems Numerous examples that use R software for all text data analyses More than 400 exercises for readers to practice and extend the theory, methods, and data analysis A supplementary website with datasets for the examples and exercises  An invaluable textbook for upper-undergraduate and graduate-level students in statistics and biostatistics courses, Foundations of Linear and Generalized Linear Models is also an excellent reference for practicing statisticians and biostatisticians, as well as anyone who is interested in learning about the most important statistical models for analyzing data.},
  googlebooks = {dgIzBgAAQBAJ},
  isbn = {978-1-118-73005-8},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes},
  language = {en}
}

@article{batesFittingLinearMixedeffects2015,
  title = {Fitting Linear Mixed-Effects Models Using Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  year = {2015},
  volume = {67},
  pages = {1--48},
  doi = {10.18637/jss.v067.i01},
  journal = {Journal of Statistical Software},
  number = {1}
}

@article{beck1998taking,
  title = {Taking Time Seriously: {{Time}}-Series-Cross-Section Analysis with a Binary Dependent Variable},
  author = {Beck, Nathaniel and Katz, Jonathan N and Tucker, Richard},
  year = {1998},
  volume = {42},
  pages = {1260--1288},
  publisher = {{JSTOR}},
  doi = {10.2307/2991857},
  journal = {American Journal of Political Science},
  number = {4}
}

@incollection{beckModellingSpaceTime1999,
  title = {Modelling Space and Time: {{The}} Event History Approach},
  booktitle = {Research Strategies in Social Science: {{A}} Guide to New Approaches},
  author = {Beck, N.},
  editor = {Scarbrough, E. and Tanenbaum, E.},
  year = {1999},
  publisher = {{Oxford University Press}},
  url = {https://doi.org/10.1093/0198292376.001.0001}
}

@book{brennanGeneralizabilityTheory2001,
  title = {Generalizability {{Theory}}},
  author = {Brennan, Robert L.},
  year = {2001},
  publisher = {{Springer-Verlag}},
  address = {{New York}},
  doi = {10.1007/978-1-4757-3456-0},
  url = {https://www.springer.com/us/book/9780387952826},
  urldate = {2020-09-17},
  abstract = {In 1972 a monograph by Cronbach, Gleser, Nanda, and Rajaratnam was published entitled The Dependability of Behavioral Measurements. That book incorporated, systematized, and extended their previous research into what came to be called generalizability theory, which liberalizes classical test theory, in part through the application of analysis of variance proce\- dures that focus on variance components. Generalizability theory is perhaps the most broadly defined measurement model currently in existence, and the Cronbach et al. (1972) treatment of the theory represents a major con\- tribution to psychometrics. However, as Cronbach et al. (1972, p. 3) state, their book is "complexly organized and by no means simple to follow" and, of course, it is nearly 30 years old. In 1983, ACT, Inc. published my monograph entitled Elements of Gen\- eralizability Theory, with a slightly revised version appearing in 1992. That treatment is considerably less comprehensive than Cronbach et al. (1972) but still detailed enough to convey much ofthe richness of the theory and to facilitate its application. However, the 1983/1992 monograph is essen\- tially two decades old, it does not cover multivariate generalizability theory in depth, and it does not incorporate recent developments in statistics that bear upon the estimation of variance components. Also, of course, there have been numerous developments in generalizability theory in the last 20 years.},
  file = {/Users/solomonkurz/Zotero/storage/PW8Z4E78/9780387952826.html},
  isbn = {978-0-387-95282-6},
  language = {en},
  series = {Statistics for {{Social}} and {{Behavioral Sciences}}}
}

@misc{BretHeather53rd,
  title = {Bret and {{Heather}} 53rd {{DarkHorse Podcast Livestream}}: {{Biden}}, {{Trump}}: {{A Case}} of {{Electile Dysfunction}}},
  shorttitle = {Bret and {{Heather}} 53rd {{DarkHorse Podcast Livestream}}},
  url = {https://www.youtube.com/watch?v=JZ5iWpoN89k&t=4711s},
  urldate = {2020-11-10},
  abstract = {In this 53rd in a series of live discussions with Bret Weinstein and Heather Heying (both PhDs in Biology), we discuss the state of the world though an evolutionary lens. In this episode, we discuss the presidential election, the ``Trump Accountability Project,'' read-only activism, and news from the streets and politics of Portland and Oregon\textemdash some of it even good (thank you Mingus Mapps, and also Governor Brown)! Also: reviews of perfumes, obviously. Find more from us on Bret's website (https://bretweinstein.net) or Heather's website (http://heatherheying.com). Become a member of the DarkHorse LiveStreams, and get access to an additional Q\&amp;A livestream every month. Join at Heather's Patreon. Like this content? Subscribe to the channel, like this video, follow us on twitter (@BretWeinstein, @HeatherEHeying), and consider helping us out by contributing to either of our Patreons or Bret's Paypal. Looking for clips from \#DarkHorseLivestreams? Here are some, updated frequently: @DarkHorse Podcast Clips Theme Music: Thank you to Martin Molin of Wintergatan for providing us the rights to use their excellent music. Q\&amp;A Link: https://youtu.be/26q3uImFgkg Mentioned in this episode: The Trump Accountability Project: https://www.trumpaccountability.net On the dangers of read-only activism, Heather's take in Medium: https://medium.com/@heyingh/on-the-da... Portland Protests and Mingus Mapps: https://www.wweek.com/news/city/2020/... Nancy Rommelmann in Reason on the situation in Portland: https://reason.com/2020/11/06/even-wi... Perfumes: The Guide. By Luca Turin and Tania Sanchez. 2018}
}

@article{Brilleman2019EstimatingSurvival,
  title = {Estimating Survival (Time-to-Event) Models with Rstanarm},
  author = {Brilleman, Sam},
  year = {2019},
  url = {https://github.com/stan-dev/rstanarm/blob/feature/frailty-models/vignettes/surv.Rmd}
}

@article{brilleman2020BayesianSurvivalAnalysis,
  title = {Bayesian Survival Analysis Using the {{rstanarm R}} Package},
  author = {Brilleman, Samuel L. and Elci, Eren M. and Novik, Jacqueline Buros and Wolfe, Rory},
  year = {2020},
  url = {https://arxiv.org/abs/2002.09633},
  archiveprefix = {arXiv},
  eprint = {2002.09633},
  eprinttype = {arxiv},
  primaryclass = {stat.CO}
}

@book{brms2021RM,
  title = {{{brms}} Reference Manual, {{Version}} 2.15.0},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  url = {https://CRAN.R-project.org/package=brms/brms.pdf}
}

@article{brownPredictorsDepressiveSymptoms1985,
  title = {Predictors of Depressive Symptoms among Unemployed {{Black}} Adults},
  author = {Brown, Diane R. and Gary, Lawrence E.},
  year = {1985},
  volume = {12},
  pages = {736},
  url = {https://scholarworks.wmich.edu/cgi/viewcontent.cgi?article=1721&amp=&context=jssw&amp=&sei-redir=1&referer=https%253A%252F%252Fscholar.google.com%252Fscholar%253Fq%253D%252522CES-D%252522%252Bunemployment%2526hl%253Den%2526as_sdt%253D0%25252C44%2526as_ylo%253D1977%2526as_yhi%253D2000#search=%22CES-D%20unemployment%22},
  file = {/Users/solomonkurz/Zotero/storage/93JB48TP/LandingPage.html},
  journal = {Journal of Sociology and Social Welfare}
}

@article{bryk1987application,
  title = {Application of Hierarchical Linear Models to Assessing Change.},
  author = {Bryk, Anthony S and Raudenbush, Stephen W},
  year = {1987},
  volume = {101},
  pages = {147},
  publisher = {{American Psychological Association}},
  doi = {10.1037/0033-2909.101.1.147},
  url = {https://personal.psu.edu/jxb14/M554/articles/Bryk%26Raudenbush1987.pdf},
  journal = {Psychological bulletin},
  number = {1}
}

@article{Bürkner2021HandleMissingValues,
  title = {Handle Missing Values with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_missings.html}
}

@article{Bürkner2021Non_linear,
  title = {Estimating Non-Linear Models with Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html}
}

@article{Bürkner2021Parameterization,
  title = {Parameterization of Response Distributions in Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=brms/vignettes/brms_families.html}
}

@article{burknerAdvancedBayesianMultilevel2018,
  title = {Advanced {{Bayesian}} Multilevel Modeling with the {{R}} Package Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2018},
  volume = {10},
  pages = {395--411},
  doi = {10.32614/RJ-2018-017},
  journal = {The R Journal},
  number = {1}
}

@article{burknerBayesianItemResponse2020,
  title = {Bayesian Item Response Modeling in {{R}} with Brms and {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  month = feb,
  url = {http://arxiv.org/abs/1905.09501},
  urldate = {2020-05-18},
  abstract = {Item Response Theory (IRT) is widely applied in the human sciences to model persons' responses on a set of items measuring one or more latent constructs. While several R packages have been developed that implement IRT models, they tend to be restricted to respective prespecified classes of models. Further, most implementations are frequentist while the availability of Bayesian methods remains comparably limited. We demonstrate how to use the R package brms together with the probabilistic programming language Stan to specify and fit a wide range of Bayesian IRT models using flexible and intuitive multilevel formula syntax. Further, item and person parameters can be related in both a linear or non-linear manner. Various distributions for categorical, ordinal, and continuous responses are supported. Users may even define their own custom response distribution for use in the presented framework. Common IRT model classes that can be specified natively in the presented framework include 1PL and 2PL logistic models optionally also containing guessing parameters, graded response and partial credit ordinal models, as well as drift diffusion models of response times coupled with binary decisions. Posterior distributions of item and person parameters can be conveniently extracted and post-processed. Model fit can be evaluated and compared using Bayes factors and efficient cross-validation procedures.},
  archiveprefix = {arXiv},
  eprint = {1905.09501},
  eprinttype = {arxiv},
  file = {/Users/solomonkurz/Zotero/storage/T5WVXMPA/Bürkner - 2020 - Bayesian Item Response Modeling in R with brms and.pdf;/Users/solomonkurz/Zotero/storage/KYB42QN2/1905.html},
  journal = {arXiv:1905.09501 [stat]},
  keywords = {Statistics - Computation},
  primaryclass = {stat}
}

@article{burknerBrmsPackageBayesian2017,
  title = {{{brms}}: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  volume = {80},
  pages = {1--28},
  doi = {10.18637/jss.v080.i01},
  journal = {Journal of Statistical Software},
  number = {1}
}

@article{capaldiPredictingTimingFirst1996,
  title = {Predicting the Timing of First Sexual Intercourse for At-Risk Adolescent Males},
  author = {Capaldi, Deborah M and Crosby, Lynn and Stoolmiller, Mike},
  year = {1996},
  volume = {67},
  pages = {344--359},
  publisher = {{JSTOR}},
  doi = {10.2307/1131818},
  journal = {Child development},
  number = {2}
}

@article{carpenterStanProbabilisticProgramming2017,
  title = {Stan: {{A}} Probabilistic Programming Language},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  volume = {76},
  publisher = {{Columbia Univ., New York, NY (United States); Harvard Univ., Cambridge, MA \ldots}},
  doi = {10.18637/jss.v076.i01},
  url = {https://www.osti.gov/servlets/purl/1430202},
  journal = {Journal of statistical software},
  number = {1}
}

@misc{CausalInferenceStatistics,
  title = {Causal {{Inference}} in {{Statistics}}: {{A Primer}} | {{Wiley}}},
  shorttitle = {Causal {{Inference}} in {{Statistics}}},
  url = {https://www.wiley.com/en-us/Causal+Inference+in+Statistics%3A+A+Primer-p-9781119186847},
  urldate = {2020-09-17},
  abstract = {Many of the concepts and terminology surrounding modern causal inference can be quite intimidating to the novice. Judea Pearl presents a book ideal for beginners in statistics, providing a comprehensive introduction to the field of causality. Examples from classical statistics are presented throughout to demonstrate the need for causality in resolving decision-making dilemmas posed by data. Causal methods are also compared to traditional statistical methods, whilst questions are provided at the end of each section to aid student learning.},
  file = {/Users/solomonkurz/Zotero/storage/BSESSITB/Causal+Inference+in+Statistics+A+Primer-p-9781119186847.html},
  journal = {Wiley.com},
  language = {en-us}
}

@article{chungNondegeneratePenalizedLikelihood2013,
  title = {A Nondegenerate Penalized Likelihood Estimator for Variance Parameters in Multilevel Models},
  author = {Chung, Yeojin and {Rabe-Hesketh}, Sophia and Dorie, Vincent and Gelman, Andrew and Liu, Jingchen},
  year = {2013},
  month = oct,
  volume = {78},
  pages = {685--709},
  issn = {0033-3123, 1860-0980},
  doi = {10.1007/s11336-013-9328-2},
  url = {http://link.springer.com/10.1007/s11336-013-9328-2},
  urldate = {2020-05-17},
  journal = {Psychometrika},
  language = {en},
  number = {4}
}

@article{cooney1991MatchingAlcoholics,
  title = {Matching Alcoholics to Coping Skills or Interactional Therapies: {{Two}}-Year Follow-up Results},
  author = {Cooney, Ned L and Kadden, Ronald M and Litt, Mark D and Getter, Herbert},
  year = {1991},
  volume = {59},
  pages = {598},
  publisher = {{American Psychological Association}},
  doi = {10.1037/0022-006X.59.4.598},
  journal = {Journal of Consulting and Clinical Psychology},
  number = {4}
}

@article{cox1972regression,
  title = {Regression Models and Life-Tables},
  author = {Cox, David R},
  year = {1972},
  volume = {34},
  pages = {187--202},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/j.2517-6161.1972.tb00899.x},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  number = {2}
}

@book{cox1984analysis,
  title = {Analysis of Survival Data},
  author = {Cox, David Roxbee and Oakes, David},
  year = {1984},
  volume = {21},
  publisher = {{CRC Press}},
  url = {https://www.routledge.com/Analysis-of-Survival-Data/Cox-Oakes/p/book/9780412244902},
  isbn = {978-0-412-24490-2}
}

@article{cranfordProcedureEvaluatingSensitivity2006,
  title = {A Procedure for Evaluating Sensitivity to Within-Person Change: {{Can}} Mood Measures in Diary Studies Detect Change Reliably?},
  shorttitle = {A {{Procedure}} for {{Evaluating Sensitivity}} to {{Within}}-{{Person Change}}},
  author = {Cranford, James A. and Shrout, Patrick E. and Iida, Masumi and Rafaeli, Eshkol and Yip, Tiffany and Bolger, Niall},
  year = {2006},
  month = jul,
  volume = {32},
  pages = {917--929},
  publisher = {{SAGE Publications Inc}},
  issn = {0146-1672},
  doi = {10.1177/0146167206287721},
  url = {https://doi.org/10.1177/0146167206287721},
  urldate = {2020-09-17},
  abstract = {The recent growth in diary and experience sampling research has increased research attention on how people change over time in natural settings. Often however, the measures in these studies were originally developed for studying between-person differences, and their sensitivity to within-person changes is usually unknown. Using a Generalizability Theory framework, the authors illustrate a procedure for developing reliable measures of change using a version of the Profile of Mood States (POMS; McNair, Lorr, \& Droppleman, 1992) shortened for diary studies. Analyzing two data sets, one composed of 35 daily reports from 68 persons experiencing a stressful examination and another composed of daily reports from 164 persons over a typical 28-day period, we demonstrate that three-item measures of anxious mood, depressed mood, anger, fatigue, and vigor have appropriate reliability to detect within-person change processes.},
  file = {/Users/solomonkurz/Zotero/storage/FLCYL85F/Cranford et al. - 2006 - A Procedure for Evaluating Sensitivity to Within-P.pdf},
  journal = {Personality and Social Psychology Bulletin},
  language = {en},
  number = {7}
}

@book{cronbachDependabilityBehavioralMeasurements1972,
  title = {The Dependability of Behavioral Measurements: {{Theory}} of Generalizability for Scores and Profiles},
  shorttitle = {The {{Dependability}} of {{Behavioral Measurements}}},
  author = {Cronbach, Lee J. and Gleser, Goldine C. and Nanda, Harinder and Rajaratnam, Nageswari},
  year = {1972},
  month = jan,
  publisher = {{John Wiley \& Sons}},
  address = {{New York}},
  url = {https://www.amazon.com/Dependability-Behavioral-Measurements-Generalizability-Profiles/dp/0471188506},
  abstract = {The Dependability of Behavioral Measurements: Theory of Generalizability for Scores and Profiles [hardcover] Lee J. Cronbach,Goldine C. Gleser,Harinder Nanda,Nageswari Rajaratnam [Jun 14, 1972]},
  isbn = {978-0-471-18850-6},
  language = {English}
}

@article{diekmann1996social,
  title = {Social Status and Aggression: {{A}} Field Study Analyzed by Survival Analysis},
  author = {Diekmann, Andreas and {Jungbauer-Gans}, Monika and Krassnig, Heinz and Lorenz, Sigrid},
  year = {1996},
  volume = {136},
  pages = {761--768},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/00224545.1996.9712252},
  journal = {The Journal of social psychology},
  number = {6}
}

@book{enders2010applied,
  title = {Applied Missing Data Analysis},
  author = {Enders, Craig K},
  year = {2010},
  publisher = {{Guilford press}},
  url = {http://www.appliedmissingdata.com/},
  isbn = {978-1-60623-639-0}
}

@article{flinnNewMethodsAnalyzing1982,
  title = {New Methods for Analyzing Individual Event Histories},
  author = {Flinn, Christopher J. and Heckman, James J.},
  year = {1982},
  volume = {13},
  pages = {99--140},
  publisher = {{[American Sociological Association, Wiley, Sage Publications, Inc.]}},
  issn = {0081-1750},
  doi = {10.2307/270719},
  url = {https://www.jstor.org/stable/270719},
  urldate = {2020-09-22},
  journal = {Sociological Methodology}
}

@article{frank1984academic,
  title = {Academic Abilities of Persons Entering and Remaining in Special Education.},
  author = {Frank, Alan R and Keith, Timothy Z},
  year = {1984},
  volume = {51},
  pages = {76--77},
  publisher = {{ERIC}},
  url = {https://eric.ed.gov/?id=EJ306852},
  journal = {Exceptional Children},
  number = {1}
}

@article{frankAcademicAbilitiesPersons1984,
  title = {Academic {{Abilities}} of {{Persons Entering}} and {{Remaining}} in {{Special Education}}},
  author = {Frank, Alan R. and Keith, Timothy Z.},
  year = {1984},
  volume = {51},
  pages = {76--77},
  abstract = {Results of the study revealed no decline in Scholastic Aptitude Test verbal or math ability scores of students completing special education teacher training programs between 1975-76 and 1980-81. Substantially more middle- and high-academic ability than low-ability teachers left special education teaching. (CL)},
  file = {/Users/solomonkurz/Zotero/storage/I7ILSTIF/eric.ed.gov.html},
  journal = {Exceptional Children},
  keywords = {Academic Ability,Disabilities,Faculty Mobility,Special Education Teachers,Teacher Characteristics},
  language = {en},
  number = {1}
}

@article{gabry2019visualization,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  volume = {182},
  pages = {389--402},
  publisher = {{Wiley Online Library}},
  doi = {10.1111/rssa.12378},
  url = {https://arxiv.org/abs/1709.01449},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  number = {2}
}

@article{gabryVisualMCMC2020,
  title = {Visual {{MCMC}} Diagnostics Using the Bayesplot Package},
  author = {Gabry, Jonah and Modr{\'a}k, Martin},
  year = {2020},
  month = may,
  url = {https://CRAN.R-project.org/package=bayesplot/vignettes/visual-mcmc-diagnostics.html}
}

@misc{gamseEvaluationSpencerPostdoctoral1997,
  title = {An Evaluation of the {{Spencer}} Post-Doctoral Dissertation Program},
  author = {Gamse, B. C. and Conger, D.},
  year = {1997},
  publisher = {{Abt Associates}}
}

@book{gelman2013bayesian,
  title = {Bayesian Data Analysis},
  author = {Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year = {2013},
  edition = {Third Edition},
  publisher = {{CRC press}},
  url = {https://stat.columbia.edu/~gelman/book/}
}

@book{gelmanDataAnalysisUsing2006,
  title = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
  author = {Gelman, Andrew and Hill, Jennifer},
  year = {2006},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511790942},
  url = {https://www.cambridge.org/core/books/data-analysis-using-regression-and-multilevelhierarchical-models/32A29531C7FD730C3A68951A17C9D983},
  urldate = {2020-09-17},
  abstract = {Data Analysis Using Regression and Multilevel/Hierarchical Models, first published in 2007, is a comprehensive manual for the applied researcher who wants to perform data analysis using linear and nonlinear regression and multilevel models. The book introduces a wide variety of models, whilst at the same time instructing the reader in how to fit these models using available software packages. The book illustrates the concepts by working through scores of real data examples that have arisen from the authors' own applied research, with programming codes provided for each one. Topics covered include causal inference, including regression, poststratification, matching, regression discontinuity, and instrumental variables, as well as multilevel logistic regression and missing-data imputation. Practical tips regarding building, fitting, and understanding are provided throughout.},
  file = {/Users/solomonkurz/Zotero/storage/KFY9IC96/32A29531C7FD730C3A68951A17C9D983.html},
  isbn = {978-0-521-86706-1},
  series = {Analytical {{Methods}} for {{Social Research}}}
}

@book{gelmanRegressionOtherStories2020,
  title = {Regression and Other Stories},
  author = {Gelman, Andrew and Hill, Jennifer and Vehtari, Aki},
  year = {2020},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/9781139161879},
  url = {https://www.cambridge.org/core/books/regression-and-other-stories/DD20DD6C9057118581076E54E40C372C},
  urldate = {2020-12-09},
  abstract = {Most textbooks on regression focus on theory and the simplest of examples. Real statistical problems, however, are complex and subtle. This is not a book about the theory of regression. It is about using regression to solve real problems of comparison, estimation, prediction, and causal inference. Unlike other books, it focuses on practical issues such as sample size and missing data and a wide range of goals and techniques. It jumps right in to methods and computer code you can use immediately. Real examples, real stories from the authors' experience demonstrate what regression can do and its limitations, with practical advice for understanding assumptions and implementing methods for experiments and observational studies. They make a smooth transition to logistic regression and GLM. The emphasis is on computation in R and Stan rather than derivations, with code available online. Graphics and presentation aid understanding of the models and model fitting.},
  file = {/Users/solomonkurz/Zotero/storage/GQITHSNF/DD20DD6C9057118581076E54E40C372C.html},
  isbn = {978-1-107-02398-7},
  series = {Analytical {{Methods}} for {{Social Research}}}
}

@article{gelmanRsquaredBayesianRegression2019,
  title = {R-Squared for {{Bayesian}} Regression Models},
  author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Vehtari, Aki},
  year = {2019},
  month = jul,
  volume = {73},
  pages = {307--309},
  issn = {0003-1305, 1537-2731},
  doi = {10.1080/00031305.2018.1549100},
  url = {https://www.tandfonline.com/doi/full/10.1080/00031305.2018.1549100},
  urldate = {2020-05-16},
  journal = {The American Statistician},
  language = {en},
  number = {3}
}

@book{gilksMCMCinPractice1995,
  title = {Markov Chain {{Monte Carlo}} in Practice},
  author = {Gilks, W.R. and Richardson, S. and Spiegelhalter, David},
  year = {1995},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://www.routledge.com/Markov-Chain-Monte-Carlo-in-Practice/Gilks-Richardson-Spiegelhalter/p/book/9780412055515},
  urldate = {2020-09-17},
  isbn = {978-0-412-05551-5},
  language = {English}
}

@article{ginexiDepressionControlBeliefs2000,
  title = {Depression and Control Beliefs in Relation to Reemployment: {{What}} Are the Directions of Effect?},
  shorttitle = {Depression and Control Beliefs in Relation to Reemployment},
  author = {Ginexi, Elizabeth M. and Howe, George W. and Caplan, Robert D.},
  year = {2000},
  volume = {5},
  pages = {323--336},
  publisher = {{Educational Publishing Foundation}},
  address = {{US}},
  issn = {1939-1307(Electronic),1076-8998(Print)},
  doi = {10.1037/1076-8998.5.3.323},
  url = {https://www.researchgate.net/profile/Elizabeth_Ginexi/publication/12406334_Depression_and_control_beliefs_in_relation_to_reemployment_What_are_the_directions_of_effect/links/553e47930cf20184050e15ed/Depression-and-control-beliefs-in-relation-to-reemployment-What-are-the-directions-of-effect.pdf},
  abstract = {Depressive symptoms, locus of control, and reemployment were assessed over the course of 1 year among 254 recently unemployed men and women. Individual growth curve modeling and discrete-time survival analyses were used to examine (a) whether reemployment resolved depressive symptoms or affected control beliefs, (b) whether depressive symptoms or control beliefs predicted time to reemployment, and (c) if these relationships changed over time. Depressive symptom declines were predicted by reemployment, but initial depression was completely unrelated to time to reemployment. Control beliefs were stable over time and thus not affected by reemployment. Instead, they predicted early reemployment. These processes varied according to reemployment type and time period. Implications for intervention and for stress and coping theory are discussed. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/ZDWHCFGS/2000-07884-001.html},
  journal = {Journal of Occupational Health Psychology},
  keywords = {Depression (Emotion),Employment Status,Internal External Locus of Control,Reemployment,Symptoms},
  number = {3}
}

@phdthesis{graham1997exodus,
  title = {The Exodus from Mathematics: {{When}} and Why?},
  author = {Graham, Suzanne E},
  year = {1997},
  school = {Harvard Graduate School of Education}
}

@article{greenwood1926NaturalDuration,
  title = {The Natural Duration of Cancer},
  author = {Greenwood, Major},
  year = {1926},
  volume = {33},
  pages = {1--26},
  publisher = {{Her Majesty's Stationery Office}},
  journal = {Reports on Public Health and Medical Subjects}
}

@article{head1975review,
  title = {A Review of Response Surface Methodology from a Biometric Point of View},
  author = {Head, R and Pike, DJ},
  year = {1975},
  volume = {31},
  pages = {803--851},
  journal = {Biometrics}
}

@book{heckman1984longitudinal,
  title = {Longitudinal Analysis of Labor Market Data},
  editor = {Heckman, James and Singer, Burton S},
  year = {1984},
  publisher = {{Cambridge University Press}},
  url = {https://doi.org/10.1017/CCOL0521304539}
}

@article{huEstimationTruncatedLifetime1996,
  title = {Estimation from Truncated Lifetime Data with Supplementary Information on Covariates and Censoring Times},
  author = {Hu, X. Joan and Lawless, Jerald F.},
  year = {1996},
  month = dec,
  volume = {83},
  pages = {747--761},
  publisher = {{Oxford Academic}},
  issn = {0006-3444},
  doi = {10.1093/biomet/83.4.747},
  url = {http://people.stat.sfu.ca/~joanh/jhpaper/HuLawless_1996Biomk.pdf},
  urldate = {2020-09-22},
  abstract = {Abstract.  In epidemiology, reliability and other areas one encounters situations where response times and covariates for individuals in a population are observ},
  file = {/Users/solomonkurz/Zotero/storage/XDGE4A66/Hu and Lawless - 1996 - Estimation from truncated lifetime data with suppl.pdf;/Users/solomonkurz/Zotero/storage/RXJWERRF/253343.html},
  journal = {Biometrika},
  language = {en},
  number = {4}
}

@article{jaegerR2StatisticFixed2017,
  title = {An {{R2}} Statistic for Fixed Effects in the Generalized Linear Mixed Model},
  author = {Jaeger, Byron C. and Edwards, Lloyd J. and Das, Kalyan and Sen, Pranab K.},
  year = {2017},
  month = apr,
  volume = {44},
  pages = {1086--1105},
  publisher = {{Taylor \& Francis}},
  issn = {0266-4763},
  doi = {10.1080/02664763.2016.1193725},
  url = {https://www.researchgate.net/publication/303887200_An_R_2_statistic_for_fixed_effects_in_the_generalized_linear_mixed_model},
  urldate = {2020-09-17},
  abstract = {Measuring the proportion of variance explained (R2) by a statistical model and the relative importance of specific predictors (semi-partial R2) can be essential considerations when building a parsimonious statistical model. The R2 statistic is a familiar summary of goodness-of-fit for normal linear models and has been extended in various ways to more general models. In particular, the generalized linear mixed model (GLMM) extends the normal linear model and is used to analyze correlated (hierarchical), non-normal data structures. Although various R2 statistics have been proposed, there is no consensus in statistical literature for the most sensible definition of R2 in this context. This research aims to build upon existing knowledge and definitions of R2 and to concisely define the statistic for the GLMM. Here, we derive a model and semi-partial R2 statistic for fixed (population) effects in the GLMM by utilizing the penalized quasi-likelihood estimation method based on linearization. We show that our proposed R2 statistic generalizes the widely used marginal R2 statistic introduced by Nakagawa and Schielzeth, demonstrate our statistics capability in model selection, show the utility of semi-partial R2 statistics in longitudinal data analysis, and provide software that computes the proposed R2 statistic along with semi-partial R2 for individual fixed effects. The software provided is adapted for both SAS and R programming languages.},
  annotation = {\_eprint: https://doi.org/10.1080/02664763.2016.1193725},
  file = {/Users/solomonkurz/Zotero/storage/82SECBMK/02664763.2016.html},
  journal = {Journal of Applied Statistics},
  keywords = {62-07,62Fxx,62Hxx,62Pxx,Blood pressure,clustered data,generalized linear mixed model,R-squared,statistical software},
  number = {6}
}

@article{kaplan1958NonparametricEstimation,
  title = {Nonparametric Estimation from Incomplete Observations},
  author = {Kaplan, Edward L and Meier, Paul},
  year = {1958},
  volume = {53},
  pages = {457--481},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/01621459.1958.10501452},
  journal = {Journal of the American statistical association},
  number = {282}
}

@article{keiley2000cross,
  title = {A Cross-Domain Growth Analysis: {{Externalizing}} and Internalizing Behaviors during 8 Years of Childhood},
  author = {Keiley, Margaret Kraatz and Bates, John E and Dodge, Kenneth A and Pettit, Gregory S},
  year = {2000},
  volume = {28},
  pages = {161--179},
  publisher = {{Springer}},
  doi = {10.1023/A:1005122814723},
  journal = {Journal of abnormal child psychology},
  number = {2}
}

@unpublished{keileyChildAbuseNeglect2002,
  title = {Child Abuse, Neglect, and Juvenile Delinquency: {{How}} ``New'' Statistical Approaches Can Inform Our Understanding of ``Old'' Questions\textemdash{{A}} Reanalysis of {{Widom}}, 1989},
  author = {Keiley, M. K. and Martin, N. C.},
  year = {2002},
  type = {Manuscript Submitted for Publication}
}

@book{kreftComparingFourDifferent1990,
  title = {Comparing Four Different Statistical Packages for Hierarchical Linear Regression: {{GENMOD}}, {{HLM}}, {{ML2}}, and {{VARCL}}},
  shorttitle = {Comparing {{Four Different Statistical Packages}} for {{Hierarchical Linear Regression}}},
  author = {Kreft, Ita G. G. and {de Leeuw}, Jan},
  year = {1990},
  month = feb,
  publisher = {{CSE Dissemination Office, UCLA Graduate School of Education, 405 Hilgard Avenue, Los Angeles, CA 90024-1521.}},
  url = {https://files.eric.ed.gov/fulltext/ED340731.pdf},
  urldate = {2020-09-17},
  abstract = {An overview is given of the available statistical theory and software for analyzing hierarchically nested data. Programs are evaluated, and general techniques are proposed to analyze data from several domains. This research is part of a larger project to evaluate elementary education in the Netherlands. The models discussed are the random coefficient models, the hierarchical mixed linear models, and the multilevel linear models. The abstract characteristics of the three classes of models and the systematic treatment of random and non-random parts of each class are described. Transformation of the models and the likelihood function are considered. The following four computer programs, using various types of algorithms, are discussed: (1) GENMOD; (2) HLM; (3) ML2; and (4) VARCL.  Each is compared for design, implementation, performance and results, and ease of use. To overcome some of the disadvantages of these techniques, a new program, MULTIPATH, is proposed for a more general approach to the analysis of data from different domains. Thirteen data tables and a 61-item list of references are included. (SLD)},
  file = {/Users/solomonkurz/Zotero/storage/R6QX9T5E/Kreft and And Others - 1990 - Comparing Four Different Statistical Packages for .pdf;/Users/solomonkurz/Zotero/storage/ES622HED/eric.ed.gov.html},
  keywords = {Comparative Analysis,Computer Software,Computer Software Evaluation,Educational Assessment,Elementary Education,Equations (Mathematics),Foreign Countries,Mathematical Models,Regression (Statistics)},
  language = {en}
}

@book{kreftIntroducingMultilevelModeling1998,
  title = {Introducing Multilevel Modeling},
  author = {Kreft, Ita G. and {de Leeuw}, Jan},
  year = {1998},
  publisher = {{SAGE Publications, Inc}},
  doi = {https://dx.doi.org/10.4135/9781849209366},
  url = {https://methods.sagepub.com/book/introducing-multilevel-modeling},
  urldate = {2020-09-17},
  isbn = {978-1-84920-936-6},
  language = {English}
}

@article{kruschkeBayesianNewStatistics2018,
  title = {{{The Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  year = {2018},
  month = feb,
  volume = {25},
  pages = {178--206},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  url = {https://link.springer.com/content/pdf/10.3758/s13423-016-1221-4.pdf},
  urldate = {2020-05-18},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  file = {/Users/solomonkurz/Zotero/storage/SRKQT967/Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {1}
}

@book{kruschkeDoingBayesianData2015,
  title = {Doing {{Bayesian}} Data Analysis: {{A}} Tutorial with {{R}}, {{JAGS}}, and {{Stan}}},
  author = {Kruschke, John K.},
  year = {2015},
  publisher = {{Academic Press}},
  url = {https://sites.google.com/site/doingbayesiandataanalysis/}
}

@book{kurzStatisticalRethinkingBrms2020,
  title = {Statistical Rethinking with Brms, {{ggplot2}}, and the Tidyverse},
  author = {Kurz, A. Solomon},
  year = {2020},
  month = mar,
  edition = {version 1.2.0},
  doi = {10.5281/zenodo.3693202},
  url = {https://bookdown.org/content/3890/},
  urldate = {2020-05-16},
  abstract = {This project is an attempt to re-express the code in McElreath's textbook. His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.},
  file = {/Users/solomonkurz/Zotero/storage/MTCXZRHZ/3890.html}
}

@book{kurzStatisticalRethinkingSecondEd2021,
  title = {Statistical Rethinking with Brms, {{ggplot2}}, and the Tidyverse: {{Second Edition}}},
  author = {Kurz, A. Solomon},
  year = {2021},
  month = mar,
  edition = {version 0.2.0},
  url = {https://bookdown.org/content/4857/},
  urldate = {2021-04-03},
  abstract = {This book is an attempt to re-express the code in the second edition of McElreath's textbook, 'Statistical rethinking.' His models are re-fit in brms, plots are redone with ggplot2, and the general data wrangling code predominantly follows the tidyverse style.}
}

@book{lambertAStudentsGuidetoBayes2018,
  title = {A Student's Guide to {{Bayesian}} Statistics},
  author = {Lambert, Ben},
  year = {2018},
  publisher = {{SAGE Publications, Inc}},
  url = {https://ben-lambert.com/a-students-guide-to-bayesian-statistics/},
  urldate = {2020-09-17},
  isbn = {978-1-4739-1635-7},
  language = {English}
}

@book{lawless1982StatisticalModels,
  title = {Statistical Models and Methods for Lifetime Data},
  author = {Lawless, Jerald F},
  year = {1982},
  publisher = {{John Wiley \& Sons}}
}

@article{liAdjustedMaximumLikelihood2010,
  title = {An Adjusted Maximum Likelihood Method for Solving Small Area Estimation Problems},
  author = {Li, Huilin and Lahiri, P.},
  year = {2010},
  month = apr,
  volume = {101},
  pages = {882--892},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2009.10.009},
  url = {http://www.sciencedirect.com/science/article/pii/S0047259X09002000},
  urldate = {2020-09-18},
  abstract = {For the well-known Fay\textendash Herriot small area model, standard variance component estimation methods frequently produce zero estimates of the strictly positive model variance. As a consequence, an empirical best linear unbiased predictor of a small area mean, commonly used in small area estimation, could reduce to a simple regression estimator, which typically has an overshrinking problem. We propose an adjusted maximum likelihood estimator of the model variance that maximizes an adjusted likelihood defined as a product of the model variance and a standard likelihood (e.g., a profile or residual likelihood) function. The adjustment factor was suggested earlier by Carl Morris in the context of approximating a hierarchical Bayes solution where the hyperparameters, including the model variance, are assumed to follow a prior distribution. Interestingly, the proposed adjustment does not affect the mean squared error property of the model variance estimator or the corresponding empirical best linear unbiased predictors of the small area means in a higher order asymptotic sense. However, as demonstrated in our simulation study, the proposed adjustment has a considerable advantage in small sample inference, especially in estimating the shrinkage parameters and in constructing the parametric bootstrap prediction intervals of the small area means, which require the use of a strictly positive consistent model variance estimate.},
  file = {/Users/solomonkurz/Zotero/storage/3V35792L/Li and Lahiri - 2010 - An adjusted maximum likelihood method for solving .pdf;/Users/solomonkurz/Zotero/storage/H5CZ5UBN/S0047259X09002000.html},
  journal = {Journal of Multivariate Analysis},
  keywords = {Adjusted density maximization estimator,Parametric bootstrap,Prediction intervals,The Fay–Herriot model},
  language = {en},
  number = {4}
}

@article{little1995ModelingDropoutMechanism,
  title = {Modeling the Drop-out Mechanism in Repeated-Measures Studies},
  author = {Little, Roderick JA},
  year = {1995},
  volume = {90},
  pages = {1112--1121},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/01621459.1995.10476615},
  journal = {Journal of the American Statistical Association},
  number = {431}
}

@book{little2019statistical,
  title = {Statistical Analysis with Missing Data},
  author = {Little, Roderick JA and Rubin, Donald B},
  year = {2019},
  edition = {third},
  volume = {793},
  publisher = {{John Wiley \& Sons}},
  url = {https://www.wiley.com/en-us/Statistical+Analysis+with+Missing+Data%2C+3rd+Edition-p-9780470526798},
  isbn = {978-0-470-52679-8}
}

@book{loo2020RM,
  title = {{{loo}} Reference Manual, {{Version}} 2.4.1},
  author = {Gabry, Jonah},
  year = {2020},
  url = {https://CRAN.R-project.org/package=loo/loo.pdf}
}

@article{lopilatoUpdatingGeneralizabilityTheory2015,
  title = {Updating Generalizability Theory in Management Research: {{Bayesian}} Estimation of Variance Components},
  shorttitle = {Updating {{Generalizability Theory}} in {{Management Research}}},
  author = {LoPilato, Alexander C. and Carter, Nathan T. and Wang, Mo},
  year = {2015},
  month = feb,
  volume = {41},
  pages = {692--717},
  publisher = {{SAGE Publications Inc}},
  issn = {0149-2063},
  doi = {10.1177/0149206314554215},
  url = {https://doi.org/10.1177/0149206314554215},
  urldate = {2020-09-17},
  abstract = {In the management literature, generalizability theory (GT) has been typically used to investigate the reliability of assessment center and job performance ratings. However, the management field has yet to take full advantage of the information GT can offer regarding the reliability of measurement. It is likely that GT has not been adopted because of the complexities involved with its notation and practical application. Moreover, current methods for obtaining accurate interval estimates around estimated variance components or their reliability coefficients are not easily implementable. Alternatively, Bayesian methods provide a different method for estimating GT variance components. Bayesian methods enable management researchers to estimate the posterior distributions of each GT variance component as well as the GT reliability coefficients. From these posterior distributions, researchers can easily obtain the interval estimates for each variance component and the corresponding reliability estimates. Conducting two studies, the authors examine what priors should be used when conducting a Bayesian GT analysis and what estimates should be used to summarize a variance component's posterior distribution. Additionally, the authors find that under certain conditions, Bayesian methods perform better than frequentist methods.},
  journal = {Journal of Management},
  language = {en},
  number = {2}
}

@article{mare1994discrete,
  title = {Discrete-Time Bivariate Hazards with Unobserved Heterogeneity: {{A}} Partially Observed Contingency Table Approach},
  author = {Mare, Robert D},
  year = {1994},
  pages = {341--383},
  publisher = {{JSTOR}},
  doi = {10.2307/270987},
  journal = {Sociological methodology}
}

@book{MASS2002,
  title = {Modern Applied Statistics with {{S}}},
  author = {Venables, W. N. and Ripley, B. D.},
  year = {2002},
  edition = {Fourth Edition},
  publisher = {{Springer}},
  address = {{New York}},
  url = {http://www.stats.ox.ac.uk/pub/MASS4}
}

@book{mcelreathStatisticalRethinkingBayesian2015,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  author = {McElreath, Richard},
  year = {2015},
  publisher = {{CRC press}},
  url = {https://xcelab.net/rm/statistical-rethinking/}
}

@book{mcelreathStatisticalRethinkingBayesian2020,
  title = {Statistical Rethinking: {{A Bayesian}} Course with Examples in {{R}} and {{Stan}}},
  shorttitle = {Statistical {{Rethinking}}},
  author = {McElreath, Richard},
  year = {2020},
  month = mar,
  edition = {Second Edition},
  publisher = {{CRC Press}},
  url = {https://xcelab.net/rm/statistical-rethinking/},
  abstract = {Statistical Rethinking: A Bayesian Course with Examples in R and Stan builds your knowledge of and confidence in making inferences from data. Reflecting the need for scripting in today's model-based statistics, the book pushes you to perform step-by-step calculations that are usually automated. This unique computational approach ensures that you understand enough of the details to make reasonable choices and interpretations in your own modeling work.  The text presents causal inference and generalized linear multilevel models from a simple Bayesian perspective that builds on information theory and maximum entropy. The core material ranges from the basics of regression to advanced multilevel models. It also presents measurement error, missing data, and Gaussian process models for spatial and phylogenetic confounding.  The second edition emphasizes the directed acyclic graph (DAG) approach to causal inference, integrating DAGs into many examples. The new edition also contains new material on the design of prior distributions, splines, ordered categorical predictors, social relations models, cross-validation, importance sampling, instrumental variables, and Hamiltonian Monte Carlo. It ends with an entirely new chapter that goes beyond generalized linear modeling, showing how domain-specific scientific models can be built into statistical analyses.  Features   Integrates working code into the main text   Illustrates concepts through worked data analysis examples   Emphasizes understanding assumptions and how assumptions are reflected in code   Offers more detailed explanations of the mathematics in optional sections   Presents examples of using the dagitty R package to analyze causal graphs   Provides the rethinking R package on the author's website and on GitHub},
  isbn = {978-0-429-63914-2},
  keywords = {Mathematics / Probability \& Statistics / General},
  language = {en}
}

@article{mcneishOnTheUnnecessaryUbiquity2017,
  title = {On the Unnecessary Ubiquity of Hierarchical Linear Modeling.},
  author = {McNeish, Daniel and Stapleton, Laura M and Silverman, Rebecca D},
  year = {2017},
  volume = {22},
  pages = {114},
  publisher = {{American Psychological Association}},
  doi = {10.1037/met0000078},
  journal = {Psychological Methods},
  number = {1}
}

@book{miller1981SurvivalAnalysis,
  title = {Survival Analysis},
  author = {Miller, Rupert G},
  year = {1981},
  publisher = {{John Wiley \& Sons}}
}

@book{millerBeyondANOVA1997,
  title = {Beyond {{ANOVA}}: {{Basics}} of Applied Statistics},
  author = {Rupert G. Miller, Jr.},
  year = {1997},
  publisher = {{Chapman and Hall/CRC}},
  url = {https://www.routledge.com/Beyond-ANOVA-Basics-of-Applied-Statistics/Jr/p/book/9780412070112},
  urldate = {2020-09-17},
  isbn = {978-0-412-07011-2},
  language = {English}
}

@article{morrisEstimatingRandomEffects2011,
  title = {Estimating Random Effects via Adjustment for Density Maximization},
  author = {Morris, Carl and Tang, Ruoxi},
  year = {2011},
  month = may,
  volume = {26},
  pages = {271--287},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/10-STS349},
  url = {https://projecteuclid.org/euclid.ss/1312204020},
  urldate = {2020-09-18},
  abstract = {We develop and evaluate point and interval estimates for the random effects \texttheta i, having made observations yi|\texttheta i {$\sim$}ind N[\texttheta i, Vi], i = 1, \ldots, k that follow a two-level Normal hierarchical model. Fitting this model requires assessing the Level-2 variance A {$\equiv$} Var(\texttheta i) to estimate shrinkages Bi {$\equiv$} Vi\,/\,(Vi + A) toward a (possibly estimated) subspace, with Bi as the target because the conditional means and variances of \texttheta i depend linearly on Bi, not on A. Adjustment for density maximization, ADM, can do the fitting for any smooth prior on A. Like the MLE, ADM bases inferences on two derivatives, but ADM can approximate with any Pearson family, with Beta distributions being appropriate because shrinkage factors satisfy 0 {$\leq$} Bi {$\leq$} 1. Our emphasis is on frequency properties, which leads to adopting a uniform prior on A {$\geq$} 0, which then puts Stein's harmonic prior (SHP) on the k random effects. It is known for the ``equal variances case'' V1 = {$\cdots$} = Vk that formal Bayes procedures for this prior produce admissible minimax estimates of the random effects, and that the posterior variances are large enough to provide confidence intervals that meet their nominal coverages. Similar results are seen to hold for our approximating ``ADM-SHP'' procedure for equal variances and also for the unequal variances situations checked here. For shrinkage coefficient estimation, the ADM-SHP procedure allows an alternative frequency interpretation. Writing L(A) as the likelihood of Bi with i fixed, ADM-SHP estimates Bi as {\^B}i = Vi\,/\,(Vi + \^A) with \^A {$\equiv$} argmax\,(A {${_\ast}$} L(A)). This justifies the term ``adjustment for likelihood maximization,'' ALM.},
  file = {/Users/solomonkurz/Zotero/storage/DAGXMQSL/Morris and Tang - 2011 - Estimating Random Effects via Adjustment for Densi.pdf;/Users/solomonkurz/Zotero/storage/UQ4M9CVV/1312204020.html},
  journal = {Statistical Science},
  keywords = {ADM,Normal multilevel model,objective Bayes,Shrinkage,Stein estimation},
  language = {EN},
  mrnumber = {MR2858514},
  number = {2},
  zmnumber = {1246.62025}
}

@book{newsom2015longitudinal,
  title = {Longitudinal Structural Equation Modeling: {{A}} Comprehensive Introduction},
  author = {Newsom, Jason T},
  year = {2015},
  publisher = {{Routledge}},
  url = {http://www.longitudinalsem.com/},
  isbn = {978-1-84872-697-0}
}

@article{nezlekMultilevelFrameworkUnderstanding2007,
  title = {A Multilevel Framework for Understanding Relationships among Traits, States, Situations and Behaviours},
  author = {Nezlek, John B.},
  year = {2007},
  volume = {21},
  pages = {789--810},
  issn = {1099-0984},
  doi = {10.1002/per.640},
  url = {https://www.researchgate.net/publication/228079300_A_Multilevel_Framework_for_Understanding_Relationships_Among_Traits_States_Situations_and_Behaviours},
  urldate = {2020-09-17},
  abstract = {A conceptual and analytic framework for understanding relationships among traits, states, situations, and behaviours is presented. The framework assumes that such relationships can be understood in terms of four questions. (1) What are the relationships between trait and state level constructs, which include psychological states, the situations people experience and behaviour? (2) What are the relationships between psychological states, between states and situations and between states and behaviours? (3) How do such state level relationships vary as a function of trait level individual differences? (4) How do the relationships that are the focus of questions 1, 2, and 3 change across time? This article describes how to use multilevel random coefficient modelling (MRCM) to examine such relationships. The framework can accommodate different definitions of traits and dispositions (Allportian, processing styles, profiles, etc.) and different ways of conceptualising relationships between states and traits (aggregationist, interactionist, etc.). Copyright \textcopyright{} 2007 John Wiley \& Sons, Ltd.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/per.640},
  copyright = {Copyright \textcopyright{} 2007 John Wiley \& Sons, Ltd.},
  file = {/Users/solomonkurz/Zotero/storage/E2MM722N/per.html},
  journal = {European Journal of Personality},
  keywords = {methods,multilevel analysis,statistical methods,traits},
  language = {en},
  number = {6}
}

@article{nosekPreregistrationRevolution2018,
  title = {The Preregistration Revolution},
  author = {Nosek, Brian A. and Ebersole, Charles R. and DeHaven, Alexander C. and Mellor, David T.},
  year = {2018},
  month = mar,
  volume = {115},
  pages = {2600--2606},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1708274114},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1708274114},
  urldate = {2020-09-17},
  abstract = {Progress in science relies in part on generating hypotheses with existing observations and testing hypotheses with new observations. This distinction between postdiction and prediction is appreciated conceptually but is not respected in practice. Mistaking generation of postdictions with testing of predictions reduces the credibility of research findings. However, ordinary biases in human reasoning, such as hindsight bias, make it hard to avoid this mistake. An effective solution is to define the research questions and analysis plan before observing the research outcomes\textemdash a process called preregistration. Preregistration distinguishes analyses and outcomes that result from predictions from those that result from postdictions. A variety of practical strategies are available to make the best possible use of preregistration in circumstances that fall short of the ideal application, such as when the data are preexisting. Services are now available for preregistration across all disciplines, facilitating a rapid increase in the practice. Widespread adoption of preregistration will increase distinctiveness between hypothesis generation and hypothesis testing and will improve the credibility of research findings.},
  file = {/Users/solomonkurz/Zotero/storage/BCF88LAV/Nosek et al. - 2018 - The preregistration revolution.pdf},
  journal = {Proceedings of the National Academy of Sciences},
  language = {en},
  number = {11}
}

@book{pearlCausalInferenceStatistics2016,
  title = {Causal {{Inference}} in {{Statistics}} - {{A Primer}}},
  author = {Pearl, Judea and Glymour, Madelyn and Jewell, Nicholas P.},
  year = {2016},
  month = mar,
  edition = {1st Edition},
  publisher = {{Wiley}},
  address = {{Chichester, West Sussex}},
  url = {https://www.wiley.com/en-us/Causal+Inference+in+Statistics%3A+A+Primer-p-9781119186847},
  abstract = {Many of the concepts and terminology surrounding modern causal inference can be quite intimidating to the novice. Judea Pearl presents a book ideal for beginners in statistics, providing a comprehensive introduction to the field of causality.~ Examples from classical statistics are presented throughout to demonstrate the need for causality in resolving decision-making dilemmas posed by data. Causal methods are also compared to traditional statistical methods, whilst questions are provided at the end of each section to aid student learning.},
  isbn = {978-1-119-18684-7},
  language = {English}
}

@book{pengProgrammingDataScience2019,
  title = {R Programming for Data Science},
  author = {Peng, Roger D.},
  year = {2019},
  url = {https://bookdown.org/rdpeng/rprogdatascience/}
}

@inproceedings{plummer2003jags,
  title = {{{JAGS}}: {{A}} Program for Analysis of {{Bayesian}} Graphical Models Using {{Gibbs}} Sampling},
  booktitle = {Proceedings of the 3rd International Workshop on Distributed Statistical Computing},
  author = {Plummer, Martyn},
  year = {2003},
  volume = {124},
  pages = {1--10},
  url = {http://www.ci.tuwien.ac.at/Conferences/DSC-2003/Drafts/Plummer.pdf},
  organization = {{Vienna, Austria}}
}

@book{plummer2012jags,
  title = {{{JAGS Version}} 3.3.0 User Manual},
  author = {Plummer, Martyn},
  year = {2012},
  url = {http://www.stat.cmu.edu/~brian/463-663/week10/articles,%20manuals/jags_user_manual.pdf}
}

@book{R-base,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2020},
  publisher = {{R Foundation for Statistical Computing}},
  address = {{Vienna, Austria}},
  url = {https://www.R-project.org/}
}

@book{R-bayesplot,
  title = {{{bayesplot}}: {{Plotting}} for {{Bayesian}} Models},
  author = {Gabry, Jonah and Mahr, Tristan},
  year = {2021},
  url = {https://CRAN.R-project.org/package=bayesplot}
}

@book{R-brms,
  title = {{{brms}}: {{Bayesian}} Regression Models Using '{{Stan}}'},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2020},
  url = {https://CRAN.R-project.org/package=brms}
}

@manual{R-broom,
  title = {{{broom}}: {{Convert}} Statistical Analysis Objects into Tidy Tibbles},
  author = {Robinson, David and Hayes, Alex},
  year = {2020},
  url = {https://CRAN.R-project.org/package=broom},
  type = {Manual}
}

@manual{R-corrr,
  title = {{{corrr}}: {{Correlations}} in {{R}}},
  author = {Kuhn, Max and Jackson, Simon and Cimentada, Jorge},
  year = {2020},
  url = {https://CRAN.R-project.org/package=corrr},
  type = {Manual}
}

@book{R-GGally,
  title = {{{GGally}}: {{Extension}} to {{'ggplot2'}}},
  author = {Schloerke, Barret and Crowley, Jason and {Di Cook} and Briatte, Francois and Marbach, Moritz and Thoen, Edwin and Elberg, Amos and Larmarange, Joseph},
  year = {2020},
  url = {https://CRAN.R-project.org/package=GGally}
}

@book{R-lme4,
  title = {{{lme4}}: {{Linear}} Mixed-Effects Models Using {{Eigen}}' and {{S4}}},
  author = {Bates, Douglas and Maechler, Martin and Bolker, Ben and Walker, Steven},
  year = {2020},
  url = {https://CRAN.R-project.org/package=lme4}
}

@book{R-loo,
  title = {{{loo}}: {{Efficient}} Leave-One-out Cross-Validation and {{WAIC}} for Bayesian Models},
  author = {Vehtari, Aki and Gabry, Jonah and Magnusson, Mans and Yao, Yuling and Gelman, Andrew},
  year = {2019},
  url = {https://CRAN.R-project.org/package=loo/}
}

@book{R-MASS,
  title = {{{MASS}}: {{Support}} Functions and Datasets for Venables and Ripley's {{MASS}}},
  author = {Ripley, Brian},
  year = {2019},
  url = {https://CRAN.R-project.org/package=MASS}
}

@book{R-metRology,
  title = {{{metRology}}: {{Support}} for Metrological Applications},
  author = {Ellison., Stephen L R},
  year = {2018},
  url = {https://CRAN.R-project.org/package=metRology}
}

@manual{R-nlme,
  title = {{{nlme}}: {{Linear}} and Nonlinear Mixed Effects Models},
  author = {Pinheiro, Jos{\'e} and Bates, Douglas and {R-core}},
  year = {2021},
  url = {https://CRAN.R-project.org/package=nlme},
  type = {Manual}
}

@book{R-patchwork,
  title = {{{patchwork}}: {{The}} Composer of Plots},
  author = {Pedersen, Thomas Lin},
  year = {2019},
  url = {https://CRAN.R-project.org/package=patchwork}
}

@book{R-posterior,
  title = {{{posterior}}: {{Tools}} for Working with Posterior Distributions},
  author = {B{\"u}rkner, Paul-Christian and Gabry, Jonah and Kay, Matthew and Vehtari, Aki},
  year = {2020},
  url = {https://mc-stan.org/posterior}
}

@book{R-psych,
  title = {{{psych}}: {{Procedures}} for Psychological, Psychometric, and Personality Research},
  author = {Revelle, William},
  year = {2020},
  url = {https://CRAN.R-project.org/package=psych}
}

@book{R-rethinking,
  title = {{{rethinking}} {{R}} Package},
  author = {McElreath, Richard},
  year = {2020},
  url = {https://xcelab.net/rm/software/}
}

@manual{R-survival,
  title = {{{survival}}: {{Survival}} Analysis},
  author = {Therneau, Terry M},
  year = {2021},
  url = {https://github.com/therneau/survival},
  type = {Manual}
}

@book{R-tidybayes,
  title = {{{tidybayes}}: {{Tidy}} Data and 'geoms' for {{Bayesian}} Models},
  author = {Kay, Matthew},
  year = {2020},
  url = {http://mjskay.github.io/tidybayes}
}

@book{R-tidyverse,
  title = {{{tidyverse}}: {{Easily}} Install and Load the 'Tidyverse'},
  author = {Wickham, Hadley},
  year = {2019},
  url = {https://CRAN.R-project.org/package=tidyverse}
}

@article{radloffCESDScaleSelfreport1977,
  title = {The {{CES}}-{{D Scale}}: {{A}} Self-Report Depression Scale for Research in the General Population},
  shorttitle = {The {{CES}}-{{D Scale}}},
  author = {Radloff, Lenore Sawyer},
  year = {1977},
  month = jun,
  volume = {1},
  pages = {385--401},
  publisher = {{SAGE Publications Inc}},
  issn = {0146-6216},
  doi = {10.1177/014662167700100306},
  url = {https://conservancy.umn.edu/bitstream/handle/11299/98561/v01n3p385.pdf?sequence=1].The},
  urldate = {2020-09-19},
  abstract = {The CES-D scale is a short self-report scale designed to measure depressive symptomatology in the general population. The items of the scale are symptoms associated with depression which have been used in previously validated longer scales. The new scale was tested in household interview surveys and in psychiatric settings. It was found to have very high internal consistency and adequate test- retest repeatability. Validity was established by pat terns of correlations with other self-report measures, by correlations with clinical ratings of depression, and by relationships with other variables which support its construct validity. Reliability, validity, and factor structure were similar across a wide variety of demographic characteristics in the general population samples tested. The scale should be a useful tool for epidemiologic studies of de pression.},
  file = {/Users/solomonkurz/Zotero/storage/X2GFW5PF/Radloff - 1977 - The CES-D Scale A Self-Report Depression Scale fo.pdf},
  journal = {Applied Psychological Measurement},
  language = {en},
  number = {3}
}

@article{raudenbushGrowthCurveAnalysis2016,
  title = {Growth Curve Analysis in Accelerated Longitudinal Designs},
  shorttitle = {Growth {{Curve Analysis}} in {{Accelerated Longitudinal Designs}}},
  author = {Raudenbush, Stephen W. and Chan, Wing-Shing},
  year = {2016},
  month = aug,
  volume = {29},
  pages = {387--411},
  publisher = {{SAGE PUBLICATIONS}},
  doi = {10.1177/0022427892029004001},
  url = {https://doi.org/10.1177/0022427892029004001},
  urldate = {2020-09-17},
  abstract = {Accelerated longitudinal designs enable researchers to study individual development over a long interval of the life course by gathering data during a comparati...},
  file = {/Users/solomonkurz/Zotero/storage/N4AMTUFZ/0022427892029004001.html},
  journal = {Journal of Research in Crime and Delinquency},
  language = {en},
  number = {4}
}

@book{raudenbushHLM2002,
  title = {Hierarchical Linear Models: {{Applications}} and Data Analysis Methods},
  author = {Raudenbush, Stephen W. and Bryk, Anthony S.},
  year = {2002},
  edition = {Second Edition},
  publisher = {{SAGE Publications, Inc}},
  url = {https://us.sagepub.com/en-us/nam/hierarchical-linear-models/book9230},
  urldate = {2020-09-17},
  isbn = {978-0-7619-1904-9},
  language = {English}
}

@article{rights2020NewRecommendations,
  title = {New Recommendations on the Use of {{R}}-Squared Differences in Multilevel Model Comparisons},
  author = {Rights, Jason D and Sterba, Sonya K},
  year = {2020},
  volume = {55},
  pages = {568--599},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/00273171.2019.1660605},
  journal = {Multivariate Behavioral Research},
  number = {4}
}

@article{rightsEffectSizeMeasures2018,
  title = {Effect Size Measures for Multilevel Models in Clinical Child and Adolescent Research: {{New}} {{R}}-Squared Methods and Recommendations},
  shorttitle = {Effect {{Size Measures}} for {{Multilevel Models}} in {{Clinical Child}} and {{Adolescent Research}}},
  author = {Rights, Jason D. and Cole, David A.},
  year = {2018},
  month = nov,
  volume = {47},
  pages = {863--873},
  publisher = {{Routledge}},
  issn = {1537-4416},
  doi = {10.1080/15374416.2018.1528550},
  url = {https://www.tandfonline.com/doi/abs/10.1080/15374416.2018.1528550},
  urldate = {2020-09-17},
  abstract = {Clinical psychologists studying child and adolescent populations commonly analyze hierarchically structured data via multilevel modeling (MLM). In clinical child and adolescent psychology, and in psychology more broadly, increasing emphasis is being placed on the reporting of effect size, such as R-squared (R2) measures of explained variance. In MLM, however, the literature on R2 had, until recently, suffered from several shortcomings: (a) the relations among existing measures were unknown, (b) methods for quantifying some types of explained variance were unavailable, (c) which (if any) measures should be used for model comparison was unclear, (d) most measures did not generalize to models with more than two levels, and (e) software to compute measures was unavailable. The purpose of this article is to summarize recent methodological developments that resolved these issues and encourage the use of MLM R2 in practice. We provide a nontechnical discussion of how the issues have been resolved and demonstrate how the new measures and methods can be implemented, highlighting their utility with an empirical example. We first consider a two-level MLM for a single hypothesized model in which we examine emotional response to social situations as a predictor of maladaptive self-cognitions, demonstrating the various ways we can quantify explained variance. We then discuss and demonstrate the use of R2 for model comparison, and discuss the extension to models with more than two levels. Last, we discuss new free software that researchers can use to compute measures and produce associated graphics.},
  annotation = {\_eprint: https://doi.org/10.1080/15374416.2018.1528550},
  file = {/Users/solomonkurz/Zotero/storage/PN5F7E5G/15374416.2018.html},
  journal = {Journal of Clinical Child \& Adolescent Psychology},
  number = {6},
  pmid = {30433818}
}

@article{rogosaGrowthCurveApproach1982,
  title = {A Growth Curve Approach to the Measurement of Change},
  author = {Rogosa, David and Brandt, David and Zimowski, Michele},
  year = {1982},
  volume = {92},
  pages = {726--748},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1455(Electronic),0033-2909(Print)},
  doi = {10.1037/0033-2909.92.3.726},
  url = {https://www.researchgate.net/publication/232478172_A_Growth_Curve_Approach_to_the_Measurement_of_Change},
  abstract = {The measurement of individual change is approached from the standpoint of individual time paths and statistical models for individual change. The authors consider both statistical and psychometric properties of measures of individual change and examine measures of change for data with more than 2 observations on each individual. It is noted that many conclusions conflict with previous behavioral science literature. (63 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/LVXIKC9M/1983-04708-001.html},
  journal = {Psychological Bulletin},
  keywords = {Behavior Change,Psychometrics,Statistical Analysis},
  number = {3}
}

@article{rogosaUnderstandingCorrelatesChange1985,
  title = {Understanding Correlates of Change by Modeling Individual Differences in Growth},
  author = {Rogosa, David R. and Willett, John B.},
  year = {1985},
  month = jun,
  volume = {50},
  pages = {203--228},
  issn = {1860-0980},
  doi = {10.1007/BF02294247},
  url = {https://gseacademic.harvard.edu/~willetjo/pdf%20files/Rogosa%20&%20Willett%201985.pdf},
  urldate = {2020-09-17},
  abstract = {The study of correlates of change is the investigation of systematic individual differences in growth. Our representation of systematic individual differences in growth is built up in two parts: (a) a model for individual growth and, (b) a model for the dependence of parameters in the individual growth models on individual characteristics. First, explicit representations of correlates of change are constructed for various models of individual growth. Second, for the special case of initial status as a correlate of change, properties of collections of growth curves provide new results on the relation between change and initial status. Third, the shortcomings of previous approaches to the assessment of correlates of change are demonstrated. In particular, correlations of residual change measures with exogenous individual characteristics are shown to be poor indicators of systematic individual differences in growth.},
  journal = {Psychometrika},
  language = {en},
  number = {2}
}

@book{rubin1987statistical,
  title = {Statistical Analysis with Missing Data},
  author = {Little, Roderick J. A. and Rubin, B., Donald},
  year = {1987},
  publisher = {{Wiley}}
}

@article{sandberg1991child,
  title = {The {{Child Behavior Checklist}} Nonclinical Standardization Samples: Should They Be Utilized as Norms?},
  author = {Sandberg, David E and {Meyer-Bahlburg}, Heino F. L. and Yager, Thomas J.},
  year = {1991},
  volume = {30},
  pages = {124--134},
  publisher = {{Elsevier}},
  doi = {10.1097/00004583-199101000-00019},
  journal = {Journal of the American Academy of Child \& Adolescent Psychiatry},
  number = {1}
}

@book{schafer1997analysis,
  title = {Analysis of Incomplete Multivariate Data},
  author = {Schafer, Joseph L},
  year = {1997},
  publisher = {{CRC press}},
  url = {https://www.routledge.com/Analysis-of-Incomplete-Multivariate-Data/Schafer/p/book/9780412040610},
  isbn = {978-0-412-04061-0}
}

@article{scheike1997discrete,
  title = {A Discrete Survival Model with Random Effects: An Application to Time to Pregnancy},
  author = {Scheike, Thomas H and Jensen, Tina Kold},
  year = {1997},
  pages = {318--329},
  publisher = {{JSTOR}},
  doi = {10.2307/2533117},
  journal = {Biometrics}
}

@incollection{shroutPsychometrics2012,
  title = {Psychometrics},
  booktitle = {Handbook of Research Methods for Studying Daily Life},
  author = {Shrout, Patrick E. and Lane, Sean P.},
  editor = {Mehl, Matthias R. and Conner, Tamlin S.},
  year = {2012},
  pages = {302--320},
  publisher = {{The Guilford Press}},
  address = {{New York, NY, US}},
  url = {https://www.guilford.com/books/Handbook-of-Research-Methods-for-Studying-Daily-Life/Mehl-Conner/9781462513055},
  abstract = {A basic provision of good research design is that measures should have good psychometric properties; that is, the measures should reflect the constructs of scientific interest and have minimal measurement error. Psychometric texts (e.g., Crocker \& Algina, 1986; Embretson \& Reise, 2000) instruct researchers on how to achieve these goals for single time point individual-difference measures, but rarely is attention paid to the psychometrics of intensive repeated measures, such as those obtained in diary studies. In this chapter we aim to provide guidelines and techniques for this special measurement context. Our focus is on the classic psychometric concepts of reliability and validity. We say that a measure is reliable when repeated applications of the measurement procedure produce the same numerical value. We say that a measure has validity if there is evidence that scores from the measurement procedure display empirical patterns that are consistent with the theoretical construct of interest. Reliability is necessary but not sufficient for validity (e.g., Shrout \& Lane, in press). It is possible to obtain a highly reliable measure that is not at all related to the construct for which it is named. We begin the chapter with a brief review of some of the special characteristics of diary studies that affect measurement quality. We then consider issues of reliability for diary data, noting that different definitions of reliability need to be used for between-person comparisons and within-person questions. Following our practical description of how to estimate reliability in diary studies, we consider issues of documenting the validity of diary measures. Throughout the chapter we illustrate the points with a numerical example based on an actual diary study. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  file = {/Users/solomonkurz/Zotero/storage/MAHLP6R3/2012-05165-017.html},
  isbn = {978-1-60918-747-7 978-1-60918-749-1},
  keywords = {Experimental Design,Experimental Psychologists,Experimentation,Journal Writing,Psychometrics,Test Reliability,Test Validity}
}

@article{singer1998PhysicianRetention,
  title = {Physician Retention in Community and Migrant Health Centers: Who Stays and for How Long?},
  author = {Singer, Judith D. and Davidson, Stephen M and Graham, Suzanne and Davidson, Harriet S},
  year = {1998},
  pages = {1198--1213},
  publisher = {{JSTOR}},
  url = {http://www.jstor.org/stable/3766886},
  journal = {Medical care}
}

@book{singerAppliedLongitudinalData2003,
  title = {Applied Longitudinal Data Analysis: {{Modeling}} Change and Event Occurrence},
  shorttitle = {Applied Longitudinal Data Analysis},
  author = {Singer, Judith D. and Willett, John B.},
  year = {2003},
  month = mar,
  publisher = {{Oxford University Press, USA}},
  url = {https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968},
  abstract = {Change is constant in everyday life. Infants crawl and then walk, children learn to read and write, teenagers mature in myriad ways, the elderly become frail and forgetful. Beyond these natural processes and events, external forces and interventions instigate and disrupt change: test scores may rise after a coaching course, drug abusers may remain abstinent after residential treatment. By charting changes over time and investigating whether and when events occur, researchers reveal the temporal rhythms of our lives. Applied Longitudinal Data Analysis is a much-needed professional book for empirical researchers and graduate students in the behavioral, social, and biomedical sciences. It offers the first accessible in-depth presentation of two of today's most popular statistical methods: multilevel models for individual change and hazard/survival models for event occurrence (in both discrete- and continuous-time). Using clear, concise prose and real data sets from published studies, the authors take you step by step through complete analyses, from simple exploratory displays that reveal underlying patterns through sophisticated specifications of complex statistical models.Applied Longitudinal Data Analysis offers readers a private consultation session with internationally recognized experts and represents a unique contribution to the literature on quantitative empirical methods.Visit http://www.ats.ucla.edu/stat/examples/alda.htm for:DT Downloadable data setsDT Library of computer programs in SAS, SPSS, Stata, HLM, MLwiN, and moreDT Additional material for data analysis},
  googlebooks = {PpnA1M8VwR8C},
  isbn = {978-0-19-515296-8},
  keywords = {Mathematics / Probability \& Statistics / General,Medical / Epidemiology,Psychology / Statistics},
  language = {en}
}

@article{singerAreSpecialEducators1992,
  title = {Are Special Educators' Career Paths Special? {{Results}} from a 13-Year Longitudinal Study},
  shorttitle = {Are {{Special Educators}}' {{Career Paths Special}}?},
  author = {Singer, Judith D.},
  year = {1992},
  volume = {59},
  pages = {262--279},
  publisher = {{SAGE PublicationsSage CA: Los Angeles, CA}},
  doi = {10.1177/001440299305900309},
  url = {https://journals.sagepub.com/doi/10.1177/001440299305900309},
  urldate = {2020-09-22},
  abstract = {A statistical methodology relatively new to education\textemdash survival analysis\textemdash is used to describe the career paths of over 6,600 special education teachers newly hire...},
  copyright = {\textcopyright{} 1992 Council for Exceptional Children},
  file = {/Users/solomonkurz/Zotero/storage/HERSASPR/001440299305900309.html},
  journal = {Exceptional Children},
  language = {en},
  number = {3}
}

@article{snijdersModeledVarianceTwolevel1994,
  title = {Modeled Variance in Two-Level Models},
  author = {Snijders, Tom A. B. and Bosker, Roel J.},
  year = {1994},
  month = feb,
  volume = {22},
  pages = {342--363},
  publisher = {{SAGE Publications Inc}},
  issn = {0049-1241},
  doi = {10.1177/0049124194022003004},
  url = {https://www.researchgate.net/publication/235726240_Modeled_Variance_in_Two-Level_Models},
  urldate = {2020-09-17},
  abstract = {The concept of explained proportion of variance or modeled proportion of variance is reviewed in the situation of the random effects hierarchical two-level model. It is argued that the proportional reduction in (estimated) variance components is not an attractive parameter to represent the joint importance of the explanatory (independent) variables for modeling the dependent variable. It is preferable instead to work with the proportional reduction in mean squared prediction error for predicting individual values (for the modeled variance at level 1) and the proportional reduction in mean squared prediction error for predicting group averages (for the modeled variance at level 2). It is shown that when predictors are added, the proportion of modeled variance defined in this way cannot go down in the population if the model is correctly specified, but can go down in a sample; the latter situation then points to the possibility of misspecification. This provides a diagnostic means for identifying misspecification.},
  journal = {Sociological Methods \& Research},
  language = {en},
  number = {3}
}

@article{sorenson1991DepressionInTheComunity,
  title = {Depression in the Community: {{An}} Investigation into Age of Onset.},
  author = {Sorenson, Susan B and Rutter, Carolyn M and Aneshensel, Carol S},
  year = {1991},
  volume = {59},
  pages = {541},
  publisher = {{American Psychological Association}},
  doi = {10.1037/0022-006X.59.4.541},
  journal = {Journal of Consulting and Clinical Psychology},
  number = {4}
}

@article{spiegelhalterBayesianMeasuresModel2002,
  title = {Bayesian Measures of Model Complexity and Fit},
  author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and Linde, Angelika Van Der},
  year = {2002},
  volume = {64},
  pages = {583--639},
  issn = {1467-9868},
  doi = {10.1111/1467-9868.00353},
  url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00353},
  urldate = {2020-06-12},
  abstract = {Summary. We consider the problem of comparing complex hierarchical models in which the number of parameters is not clearly defined. Using an information theoretic argument we derive a measure pD for the effective number of parameters in a model as the difference between the posterior mean of the deviance and the deviance at the posterior means of the parameters of interest. In general pD approximately corresponds to the trace of the product of Fisher's information and the posterior covariance, which in normal models is the trace of the `hat' matrix projecting observations onto fitted values. Its properties in exponential families are explored. The posterior mean deviance is suggested as a Bayesian measure of fit or adequacy, and the contributions of individual observations to the fit and complexity can give rise to a diagnostic plot of deviance residuals against leverages. Adding pD to the posterior mean deviance gives a deviance information criterion for comparing models, which is related to other information criteria and has an approximate decision theoretic justification. The procedure is illustrated in some examples, and comparisons are drawn with alternative Bayesian and classical proposals. Throughout it is emphasized that the quantities required are trivial to compute in a Markov chain Monte Carlo analysis.},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9868.00353},
  file = {/Users/solomonkurz/Zotero/storage/GGPTKT9M/Spiegelhalter et al. - 2002 - Bayesian measures of model complexity and fit.pdf;/Users/solomonkurz/Zotero/storage/SD8PUJGW/1467-9868.html},
  journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  keywords = {Bayesian model comparison,Decision theory,Deviance information criterion,Effective number of parameters,Hierarchical models,Information theory,Leverage,Markov chain Monte Carlo methods,Model dimension},
  language = {en},
  number = {4}
}

@article{spiegelhalterDevianceInformationCriterion2014,
  title = {The Deviance Information Criterion: 12 Years On},
  shorttitle = {The Deviance Information Criterion},
  author = {Spiegelhalter, David J. and Best, Nicola G. and Carlin, Bradley P. and {van der Linde}, Angelika},
  year = {2014},
  volume = {76},
  pages = {485--493},
  publisher = {{[Royal Statistical Society, Wiley]}},
  issn = {1369-7412},
  url = {https://www.jstor.org/stable/24774528},
  urldate = {2020-09-17},
  abstract = {The essentials of our paper of 2002 are briefly summarized and compared with other criteria for model comparison. After some comments on the paper's reception and influence, we consider criticisms and proposals for improvement made by us and others.},
  journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
  number = {3}
}

@book{standevelopmentteamStanReferenceManual2021,
  title = {Stan Reference Manual, {{Version}} 2.26},
  author = {{Stan Development Team}},
  year = {2021},
  url = {https://mc-stan.org/docs/2_26/reference-manual/}
}

@book{standevelopmentteamStanUserGuide2021,
  title = {Stan User's Guide, {{Version}} 2.26},
  author = {{Stan Development Team}},
  year = {2021},
  url = {https://mc-stan.org/docs/2_26/stan-users-guide/index.html}
}

@article{steegen2016increasing,
  title = {Increasing Transparency through a Multiverse Analysis},
  author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
  year = {2016},
  volume = {11},
  pages = {702--712},
  publisher = {{Sage Publications Sage CA: Los Angeles, CA}},
  doi = {10.1177/1745691616658637},
  url = {https://journals.sagepub.com/doi/pdf/10.1177/1745691616658637},
  journal = {Perspectives on Psychological Science},
  number = {5}
}

@article{steegenIncreasingTransparencyMultiverse2016,
  title = {Increasing {{Transparency Through}} a {{Multiverse Analysis}}:},
  shorttitle = {Increasing {{Transparency Through}} a {{Multiverse Analysis}}},
  author = {Steegen, Sara and Tuerlinckx, Francis and Gelman, Andrew and Vanpaemel, Wolf},
  year = {2016},
  month = sep,
  publisher = {{SAGE PublicationsSage CA: Los Angeles, CA}},
  doi = {10.1177/1745691616658637},
  url = {https://journals.sagepub.com/doi/10.1177/1745691616658637},
  urldate = {2020-09-17},
  abstract = {Empirical research inevitably includes constructing a data set by processing raw data into a form ready for statistical analysis. Data processing often involves...},
  copyright = {\textcopyright{} The Author(s) 2016},
  file = {/Users/solomonkurz/Zotero/storage/HZIF4LZ2/Steegen et al. - 2016 - Increasing Transparency Through a Multiverse Analy.pdf;/Users/solomonkurz/Zotero/storage/922L4QCP/1745691616658637.html},
  journal = {Perspectives on Psychological Science},
  language = {en}
}

@article{sueyoshi1995class,
  title = {A Class of Binary Response Models for Grouped Duration Data},
  author = {Sueyoshi, Glenn T},
  year = {1995},
  volume = {10},
  pages = {411--431},
  publisher = {{Wiley Online Library}},
  doi = {10.1002/jae.3950100406},
  journal = {Journal of Applied Econometrics},
  number = {4}
}

@book{survival2021RM,
  title = {{{survival}} Reference Manual, {{Version}} 3.2-10},
  author = {Therneau, Terry M.},
  year = {2021},
  url = {https://CRAN.R-project.org/package=survival/survival.pdf}
}

@book{therneau2000ModelingSurvivalData,
  title = {Modeling Survival Data: {{Extending}} the {{Cox}} Model},
  author = {Therneau, Terry M. and Grambsch, Patricia M.},
  year = {2000},
  publisher = {{Springer}},
  address = {{New York}},
  url = {https://link.springer.com/book/10.1007/978-1-4757-3294-8},
  isbn = {0-387-98784-3}
}

@book{therneau2021Package4Survival,
  title = {A Package for Survival Analysis in {{R}}},
  author = {Therneau, Terry M.},
  year = {2021},
  month = mar,
  url = {https://CRAN.R-project.org/package=survival/vignettes/survival.pdf}
}

@inproceedings{tomarken1997sleep,
  title = {Sleep Deprivation and Anti-Depressant Medication: Unique Effects on Positive and Negative Affect},
  booktitle = {American Psychological Society Meeting, Washington, {{DC}}},
  author = {Tomarken, AJ and Shelton, RC and Elkins, L and Anderson, T},
  year = {1997}
}

@article{turnbullEmpiricalDistributionFunction1976,
  title = {The Empirical Distribution Function with Arbitrarily Grouped, Censored and Truncated Data},
  author = {Turnbull, Bruce W.},
  year = {1976},
  volume = {38},
  pages = {290--295},
  issn = {2517-6161},
  doi = {10.1111/j.2517-6161.1976.tb01597.x},
  url = {https://apps.dtic.mil/dtic/tr/fulltext/u2/a030940.pdf},
  urldate = {2020-09-22},
  abstract = {This paper is concerned with the non-parametric estimation of a distribution function F, when the data are incomplete due to grouping, censoring and/or truncation. Using the idea of self-consistency, a simple algorithm is constructed and shown to converge monotonically to yield a maximum likelihood estimate of F. An application to hypothesis testing is indicated.},
  annotation = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1976.tb01597.x},
  copyright = {\textcopyright{} 1976 The Authors},
  file = {/Users/solomonkurz/Zotero/storage/85H3LLZ6/j.2517-6161.1976.tb01597.html},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  keywords = {censoring,empirical distribution function,grouping,kaplan–meier product limit estimator,logrank test,maximum likelihood,multinomial distribution,newton–raphson,self-consistency,survival curve,truncation},
  language = {en},
  number = {3}
}

@article{turnbullNonparametricEstimationSurvivorship1974,
  title = {Nonparametric Estimation of a Survivorship Function with Doubly Censored Data},
  author = {Turnbull, Bruce W.},
  year = {1974},
  month = mar,
  volume = {69},
  pages = {169--173},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.1974.10480146},
  url = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1974.10480146},
  urldate = {2020-09-22},
  abstract = {A simple iterative procedure is proposed for obtaining estimates of a response time distribution when some of the data are censored on the left and some on the right. The procedure is based on the product-limit method of Kaplan and Meier [15], and it also uses the idea of self-consistency due to Efron [8]. Under fairly general assumptions, the method is shown to yield unique consistent maximum likelihood estimators. Asymptotic expressions for their variances and covariances are derived and an extension to the case of arbitrary censoring is suggested.},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/01621459.1974.10480146},
  file = {/Users/solomonkurz/Zotero/storage/SYXGC947/01621459.1974.html},
  journal = {Journal of the American Statistical Association},
  number = {345}
}

@book{vanbuurenFlexibleImputationMissing2018,
  title = {Flexible Imputation of Missing Data},
  shorttitle = {Https},
  author = {{van Buuren}, Stef},
  year = {2018},
  edition = {Second Edition},
  publisher = {{CRC Press}},
  url = {https://stefvanbuuren.name/fimd/},
  urldate = {2020-09-19},
  file = {/Users/solomonkurz/Zotero/storage/VIE7D8L2/fimd.html},
  isbn = {978-0-429-96034-5 0-429-96034-4}
}

@article{vaupel1979impact,
  title = {The Impact of Heterogeneity in Individual Frailty on the Dynamics of Mortality},
  author = {Vaupel, James W and Manton, Kenneth G and Stallard, Eric},
  year = {1979},
  volume = {16},
  pages = {439--454},
  publisher = {{Springer}},
  doi = {10.2307/2061224},
  journal = {Demography},
  number = {3}
}

@article{vaupel1985heterogeneity,
  title = {Heterogeneity's Ruses: {{Some}} Surprising Effects of Selection on Population Dynamics},
  author = {Vaupel, James W and Yashin, Anatoli I},
  year = {1985},
  volume = {39},
  pages = {176--185},
  publisher = {{Taylor \& Francis}},
  doi = {10.1080/00031305.1985.10479424},
  journal = {The American Statistician},
  number = {3}
}

@article{vehtari2021pareto,
  title = {Pareto Smoothed Importance Sampling},
  author = {Vehtari, Aki and Simpson, Daniel and Gelman, Andrew and Yao, Yuling and Gabry, Jonah},
  year = {2021},
  url = {https://arxiv.org/abs/1507.02646},
  archiveprefix = {arXiv},
  eprint = {1507.02646},
  eprinttype = {arxiv},
  primaryclass = {stat.CO}
}

@article{vehtariPracticalBayesianModel2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  volume = {27},
  pages = {1413--1432},
  issn = {1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  url = {https://arxiv.org/pdf/1507.04544.pdf},
  urldate = {2020-06-03},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  file = {/Users/solomonkurz/Zotero/storage/I7HY567V/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf},
  journal = {Statistics and Computing},
  language = {en},
  number = {5}
}

@article{vehtariRanknormalizationFoldingLocalization2019,
  title = {Rank-Normalization, Folding, and Localization: {{An}} Improved \$\textbackslash widehat\{\vphantom\}{{R}}\vphantom\{\}\$ for Assessing Convergence of {{MCMC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Simpson, Daniel and Carpenter, Bob and B{\"u}rkner, Paul-Christian},
  year = {2019},
  url = {https://arxiv.org/abs/1903.08008?},
  archiveprefix = {arXiv},
  eprint = {1903.08008},
  eprinttype = {arxiv},
  journal = {arXiv preprint arXiv:1903.08008}
}

@misc{vehtariUsingLooPackage2020,
  title = {Using the Loo Package (Version {$>$}= 2.0.0)},
  author = {Vehtari, Aki and Gabry, Jonah},
  year = {2020},
  month = jul,
  url = {https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html},
  urldate = {2020-09-15},
  file = {/Users/solomonkurz/Zotero/storage/QQ6SLVSV/loo2-example.html}
}

@article{watanabeAsymptoticEquivalenceBayes2010,
  title = {Asymptotic Equivalence of {{Bayes}} Cross Validation and Widely Applicable Information Criterion in Singular Learning Theory},
  author = {Watanabe, Sumio},
  year = {2010},
  volume = {11},
  pages = {3571--3594},
  issn = {1533-7928},
  url = {http://jmlr.org/papers/v11/watanabe10a.html},
  urldate = {2020-06-12},
  file = {/Users/solomonkurz/Zotero/storage/4HA4VYLM/Watanabe - 2010 - Asymptotic Equivalence of Bayes Cross Validation a.pdf;/Users/solomonkurz/Zotero/storage/MSKBHX5F/watanabe10a.html},
  journal = {Journal of Machine Learning Research},
  number = {116}
}

@incollection{wheaton1997impact,
  title = {The Impact of Twenty Childhood and Adult Traumatic Stressors on the Risk of Psychiatric Disorder},
  booktitle = {Stress and Adversity over the Life Course: {{Trajectories}} and Turning Points},
  author = {Wheaton, Blair and Roszell, Patricia and Hall, Kimberlee},
  editor = {Gotlib, I. H. and Wheaton, Blair},
  year = {1997},
  pages = {50--72},
  publisher = {{Cambridge University Press}},
  doi = {10.1017/CBO9780511527623},
  url = {https://www.cambridge.org/core/books/stress-and-adversity-over-the-life-course/8CD7EE190B912C5C7DD0B3831C95348F}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the Tidyverse},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and Fran{\c c}ois, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and M{\"u}ller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  year = {2019},
  volume = {4},
  pages = {1686},
  doi = {10.21105/joss.01686},
  journal = {Journal of Open Source Software},
  number = {43}
}

@article{willett1988QuestionsAndAnswers,
  title = {Chapter 9: {{Questions}} and Answers in the Measurement of Change},
  author = {Willett, John B.},
  year = {1988},
  volume = {15},
  pages = {345--422},
  publisher = {{American Educational Research Association}},
  doi = {10.2307/1167368},
  journal = {Review of Research in Education}
}

@article{willettResultsReliabilityLongitudinal1989,
  title = {Some Results on Reliability for the Longitudinal Measurement of Change: {{Implications}} for the Design of Studies of Individual Growth},
  shorttitle = {Some {{Results}} on {{Reliability}} for the {{Longitudinal Measurement}} of {{Change}}},
  author = {Willett, John B.},
  year = {1989},
  month = sep,
  volume = {49},
  pages = {587--602},
  publisher = {{SAGE Publications Inc}},
  issn = {0013-1644},
  doi = {10.1177/001316448904900309},
  url = {https://doi.org/10.1177/001316448904900309},
  urldate = {2020-09-17},
  abstract = {When changes in educational or psychological status are being measured, every subject in the sample must be observed on several chronologically successive occasions. In the pursuit of such longitudinal data, traditional researchers have been content to administer only a pre-test and a post-test (thus collecting two waves of data on each subject). More recently, however, methodologists have argued that multiwave data (i.e., more than two waves) must be collected for the effective measurement of change. Multi-wave data allows a suitable mathematical model to be fitted to each of the individual growth records as a way of summarizing the growth of each subject. Subsequent investigations of between-individual differences in growth can then be based on the results of these fits.In this article, individual growth-modeling permits the reliability of change measurement to be examined. This reliability is shown to depend upon three factors: the magnitude of the inter-individual heterogeneity in true growth, the size of the measurement-error variance, and the number of waves of data that have been collected. The paper demonstrates that dramatic increases in the reliability of change measurement can be achieved by collecting relatively few additional waves of data, a finding that has considerable import for the informed design of longitudinal studies of individual change.},
  journal = {Educational and Psychological Measurement},
  language = {en},
  number = {3}
}

@article{williamsSurfaceUnearthingWithinperson2019,
  title = {Beneath the Surface: {{Unearthing}} within-{{Person}} Variability and Mean Relations with {{Bayesian}} Mixed Models},
  shorttitle = {Beneath the {{Surface}}},
  author = {Williams, Donald R. and Rouder, Jeffrey and Rast, Philippe},
  year = {2019},
  month = jun,
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/gwatq},
  url = {https://osf.io/gwatq},
  urldate = {2020-08-05},
  abstract = {Mixed-effects models are becoming common in psychological science. Although they have many desirable features, there is still untapped potential that has not yet been fully realized. It is customary to view homogeneous variance as an assumption to satisfy. We argue to move beyond that perspective, and to view modeling within-person variance (``noise'') as an opportunity to gain a richer understanding of psychological processes. This can provide important insights into behavioral (in)stability. The technique to do so is based on the mixed-effects location scale model. The formulation can simultaneously estimate mixed-effects sub-models to both the mean (location) and within-person variance (scale) for clustered data common to psychology. We develop a framework that goes beyond assessing the sub-models in isolation of one another, and allows for testing structural relations between the mean and within-person variance with the Bayes factor. We first present a motivating example, which makes clear how the model can characterize mean\textendash variance relations. We then apply the method to reaction times gathered from two cognitive inference tasks. We find there are more individual differences in the within-person variance than the mean structure, as well as a complex web of structural mean\textendash variance relations in the random effects. This stands in contrast to the dominant view of within-person variance\textendash i.e., measurement ``error'' or ``noise.'' The results also point towards paradoxical within-person, as opposed to between-person, effects. That is, in both tasks, several people had \textbackslash emph\{slower\} and \textbackslash emph\{less\} variable incongruent responses. This contradicts the typical pattern, wherein \textbackslash emph\{larger\} means are expected to be \textbackslash emph\{more\} variable. We conclude with future directions. These span from methodological to theoretical inquires that can be answered with the presented methodology.}
}

@article{yaoUsingStackingAverage2018,
  title = {Using Stacking to Average {{Bayesian}} Predictive Distributions (with Discussion)},
  author = {Yao, Yuling and Vehtari, Aki and Simpson, Daniel and Gelman, Andrew},
  year = {2018},
  volume = {13},
  pages = {917--1007},
  publisher = {{International Society for Bayesian Analysis}},
  doi = {10.1214/17-BA1091},
  url = {https://projecteuclid.org/download/pdfview_1/euclid.ba/1516093227},
  journal = {Bayesian Analysis},
  number = {3}
}

@article{zorn2000CompetingRisks,
  title = {A Competing Risks Model of {{Supreme Court}} Vacancies, 1789\textendash 1992},
  author = {Zorn, Christopher JW and Van Winkle, Steven R},
  year = {2000},
  volume = {22},
  pages = {145--166},
  publisher = {{Springer}},
  doi = {10.1023/A:1006667601289},
  journal = {Political Behavior},
  number = {2}
}


